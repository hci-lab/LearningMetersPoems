
model.compile(optimizer = 'adam', loss='categorical_crossentropy',metrics = ['accuracy'] )

print(model.summary())
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_1 (LSTM)                (None, 100)               54400     
_________________________________________________________________
dense_1 (Dense)              (None, 11)                1111      
=================================================================
Total params: 55,511
Trainable params: 55,511
Non-trainable params: 0
_________________________________________________________________
None

model.fit(X_train_padded, y_train, validation_split = 0.1, epochs=20, batch_size=64)
Train on 163882 samples, validate on 18210 samples
Epoch 1/20
163882/163882 [==============================] - 818s 5ms/step - loss: 1.4202 - acc: 0.4562 - val_loss: 1.2237 - val_acc: 0.5431
Epoch 2/20
163882/163882 [==============================] - 794s 5ms/step - loss: 1.0520 - acc: 0.6232 - val_loss: 0.8609 - val_acc: 0.7074
Epoch 3/20
163882/163882 [==============================] - 789s 5ms/step - loss: 0.7641 - acc: 0.7435 - val_loss: 0.7022 - val_acc: 0.7661
Epoch 4/20
163882/163882 [==============================] - 792s 5ms/step - loss: 0.6375 - acc: 0.7906 - val_loss: 0.5935 - val_acc: 0.8071
Epoch 5/20
163882/163882 [==============================] - 803s 5ms/step - loss: 0.5508 - acc: 0.8210 - val_loss: 0.5570 - val_acc: 0.8206
Epoch 6/20
163882/163882 [==============================] - 798s 5ms/step - loss: 0.4796 - acc: 0.8465 - val_loss: 0.4771 - val_acc: 0.8462
Epoch 7/20
163882/163882 [==============================] - 802s 5ms/step - loss: 0.4256 - acc: 0.8658 - val_loss: 0.4418 - val_acc: 0.8620
Epoch 8/20
163882/163882 [==============================] - 815s 5ms/step - loss: 0.3805 - acc: 0.8816 - val_loss: 0.3996 - val_acc: 0.8789
Epoch 9/20
163882/163882 [==============================] - 793s 5ms/step - loss: 0.3459 - acc: 0.8937 - val_loss: 0.3615 - val_acc: 0.8926
Epoch 10/20
163882/163882 [==============================] - 794s 5ms/step - loss: 0.3158 - acc: 0.9042 - val_loss: 0.3547 - val_acc: 0.8917
Epoch 11/20
163882/163882 [==============================] - 789s 5ms/step - loss: 0.2922 - acc: 0.9120 - val_loss: 0.3376 - val_acc: 0.8994
Epoch 12/20
163882/163882 [==============================] - 799s 5ms/step - loss: 0.2713 - acc: 0.9181 - val_loss: 0.3270 - val_acc: 0.9012
Epoch 13/20
163882/163882 [==============================] - 789s 5ms/step - loss: 0.2537 - acc: 0.9238 - val_loss: 0.3120 - val_acc: 0.9055
Epoch 14/20
163882/163882 [==============================] - 794s 5ms/step - loss: 0.2369 - acc: 0.9296 - val_loss: 0.3079 - val_acc: 0.9097
Epoch 15/20
163882/163882 [==============================] - 790s 5ms/step - loss: 0.2227 - acc: 0.9340 - val_loss: 0.3202 - val_acc: 0.9036
Epoch 16/20
163882/163882 [==============================] - 798s 5ms/step - loss: 0.2094 - acc: 0.9382 - val_loss: 0.2985 - val_acc: 0.9132
Epoch 17/20
163882/163882 [==============================] - 788s 5ms/step - loss: 0.1981 - acc: 0.9417 - val_loss: 0.2898 - val_acc: 0.9150
Epoch 18/20
163882/163882 [==============================] - 835s 5ms/step - loss: 0.1883 - acc: 0.9447 - val_loss: 0.2872 - val_acc: 0.9162
Epoch 19/20
163882/163882 [==============================] - 801s 5ms/step - loss: 0.1786 - acc: 0.9476 - val_loss: 0.2877 - val_acc: 0.9172
Epoch 20/20
163882/163882 [==============================] - 792s 5ms/step - loss: 0.1707 - acc: 0.9503 - val_loss: 0.2911 - val_acc: 0.9182
Out[6]: <keras.callbacks.History at 0x18b7b0edcf8>


print("Accuracy: %.2f%%" % (scores[1]*100))
Accuracy: 91.76%