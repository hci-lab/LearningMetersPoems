{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import arabic\n",
    "import pyarabic\n",
    "import helpers\n",
    "#from helpers import save_h5\n",
    "from helpers import Clean_data\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "#########################\n",
    "from numpy import array, argmax\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "from pyarabic.araby import strip_tatweel\n",
    "from pyarabic.araby import strip_tashkeel\n",
    "import pickle\n",
    "##########################\n",
    "\n",
    "input_data_path = \"../data/Almoso3a_Alshe3rya/data/All_ksaied.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mostafaalaa/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import arabic\n",
    "from itertools import product \n",
    "from pyarabic.araby import strip_tashkeel, strip_tatweel\n",
    "import numpy as np\n",
    "from numpy import array\n",
    "import re\n",
    "import h5py\n",
    "\n",
    "counter = 0\n",
    "\n",
    "\n",
    "\n",
    "def save_h5(nameOfFile,nameOfDataset,dataVar):\n",
    "    h5f = h5py.File(nameOfFile, 'w')\n",
    "    h5f.create_dataset(nameOfDataset, data=dataVar)\n",
    "    h5f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mostafaalaa/anaconda3/lib/python3.6/site-packages/numpy/lib/arraysetops.py:472: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1831770 entries, 0 to 1835252\n",
      "Data columns (total 8 columns):\n",
      "العصر           object\n",
      "الشاعر          object\n",
      "الديوان         object\n",
      "القافية         object\n",
      "البحر           object\n",
      "الشطر الايسر    object\n",
      "الشطر الايمن    object\n",
      "البيت           object\n",
      "dtypes: object(8)\n",
      "memory usage: 1.8 GB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1831770, 2)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data = pd.read_csv(input_data_path, index_col=0)\n",
    "input_data.info(memory_usage='deep')\n",
    "bahr = 'Bahr'\n",
    "bayt = 'Bayt_Text'\n",
    "#input_data  = input_data[[bayt, bahr]]\n",
    "bahr = 'البحر'\n",
    "bayt = 'البيت'\n",
    "input_data  = input_data[[bayt, bahr]]\n",
    "input_data.columns = ['Bayt_Text','Bahr']\n",
    "our_alphabets = \"\".join(arabic.alphabet) + \"\".join(arabic.tashkeel)+\" \"\n",
    "our_alphabets = \"\".join(our_alphabets)\n",
    "input_data['Bayt_Text'] = input_data['Bayt_Text'].apply(lambda x: re.sub(r'[^'+our_alphabets+']','',str(x))).apply(lambda x: re.sub(r'  *',\" \",x)).apply(lambda x: re.sub(r'ّ+', 'ّ', x)).apply(lambda x: x.strip())\n",
    "input_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "الطويل          405378\n",
       "الكامل          363486\n",
       "البسيط          239974\n",
       "الخفيف          156049\n",
       "الوافر          140560\n",
       "الرجز           117572\n",
       "&nbsp;           92334\n",
       "الرمل            79015\n",
       "المتقارب         63818\n",
       "السريع           58084\n",
       "موشح             30060\n",
       "المنسرح          28357\n",
       "المجتث           17884\n",
       "المديد            7829\n",
       "الهزج             7541\n",
       "عامي              7074\n",
       "المتدارك          5037\n",
       "شعر التفعيلة      3232\n",
       "الدوبيت           2713\n",
       "شعر حر            2135\n",
       "المواليا          1644\n",
       "السلسلة            907\n",
       "المقتضب            799\n",
       "المضارع            288\n",
       "Name: Bahr, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data.iloc[:, 1].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bayt_Text</th>\n",
       "      <th>Bahr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>خَليلَيَّ لا تَستَعجِلا أَن تَزَوَّدا وَأَن تَ...</td>\n",
       "      <td>الطويل</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>فَما لَبَثٌ يَوماً بِسابِقٍ مَغنَمٍ وَلا سُرعَ...</td>\n",
       "      <td>الطويل</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>وَإِن تُنظِراني اليَومَ أَقضِ لُبانَةً وَتَستَ...</td>\n",
       "      <td>الطويل</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>لَعَمرُكَ ما نَفسٌ بِجِدٍ رَشيدَةٍ تُؤامِرُني ...</td>\n",
       "      <td>الطويل</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>وَإِن ظَهَرَت مِنهُ قَوارِصُ جَمَّةٌ وَأَفرَعَ...</td>\n",
       "      <td>الطويل</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Bayt_Text    Bahr\n",
       "0  خَليلَيَّ لا تَستَعجِلا أَن تَزَوَّدا وَأَن تَ...  الطويل\n",
       "1  فَما لَبَثٌ يَوماً بِسابِقٍ مَغنَمٍ وَلا سُرعَ...  الطويل\n",
       "2  وَإِن تُنظِراني اليَومَ أَقضِ لُبانَةً وَتَستَ...  الطويل\n",
       "3  لَعَمرُكَ ما نَفسٌ بِجِدٍ رَشيدَةٍ تُؤامِرُني ...  الطويل\n",
       "4  وَإِن ظَهَرَت مِنهُ قَوارِصُ جَمَّةٌ وَأَفرَعَ...  الطويل"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['الوافر',\n",
       " 'المنسرح',\n",
       " 'المديد',\n",
       " 'المجتث',\n",
       " 'المتقارب',\n",
       " 'الكامل',\n",
       " 'الطويل',\n",
       " 'السريع',\n",
       " 'الرمل',\n",
       " 'الرجز',\n",
       " 'الخفيف',\n",
       " 'البسيط']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "elminated_classic_bohor = ['الوافر', 'المنسرح', 'المديد', 'المجتث', 'المتقارب', 'الكامل', 'الطويل', 'السريع', 'الرمل',\n",
    "                         'الرجز', 'الخفيف', 'البسيط']\n",
    "\n",
    "elminated_classic_bohor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['الوافر',\n",
       " 'المنسرح',\n",
       " 'المديد',\n",
       " 'المجتث',\n",
       " 'المتقارب',\n",
       " 'الكامل',\n",
       " 'الطويل',\n",
       " 'السريع',\n",
       " 'الرمل',\n",
       " 'الرجز',\n",
       " 'الخفيف',\n",
       " 'البسيط',\n",
       " 'المقتضب',\n",
       " 'الهزج',\n",
       " 'المضارع',\n",
       " 'المتدارك']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_bohor_classes = ['الوافر', 'المنسرح', 'المديد', 'المجتث', 'المتقارب', 'الكامل', 'الطويل', 'السريع', 'الرمل',\n",
    "                         'الرجز', 'الخفيف', 'البسيط', 'المقتضب', 'الهزج', 'المضارع', 'المتدارك']\n",
    "full_bohor_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mostafaalaa/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bayt_Text</th>\n",
       "      <th>Bahr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>خَليلَيَّ لا تَستَعجِلا أَن تَزَوَّدا وَأَن تَ...</td>\n",
       "      <td>الطويل</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>فَما لَبَثٌ يَوماً بِسابِقٍ مَغنَمٍ وَلا سُرعَ...</td>\n",
       "      <td>الطويل</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>وَإِن تُنظِراني اليَومَ أَقضِ لُبانَةً وَتَستَ...</td>\n",
       "      <td>الطويل</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>لَعَمرُكَ ما نَفسٌ بِجِدٍ رَشيدَةٍ تُؤامِرُني ...</td>\n",
       "      <td>الطويل</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>وَإِن ظَهَرَت مِنهُ قَوارِصُ جَمَّةٌ وَأَفرَعَ...</td>\n",
       "      <td>الطويل</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Bayt_Text    Bahr\n",
       "0  خَليلَيَّ لا تَستَعجِلا أَن تَزَوَّدا وَأَن تَ...  الطويل\n",
       "1  فَما لَبَثٌ يَوماً بِسابِقٍ مَغنَمٍ وَلا سُرعَ...  الطويل\n",
       "2  وَإِن تُنظِراني اليَومَ أَقضِ لُبانَةً وَتَستَ...  الطويل\n",
       "3  لَعَمرُكَ ما نَفسٌ بِجِدٍ رَشيدَةٍ تُؤامِرُني ...  الطويل\n",
       "4  وَإِن ظَهَرَت مِنهُ قَوارِصُ جَمَّةٌ وَأَفرَعَ...  الطويل"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_filtered_data = input_data.loc[input_data['Bahr'].isin(full_bohor_classes)]\n",
    "full_filtered_data['Bayt_Text'] = full_filtered_data['Bayt_Text'].apply(pyarabic.araby.strip_tatweel)\n",
    "full_filtered_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mostafaalaa/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bayt_Text</th>\n",
       "      <th>Bahr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>خَليلَيَّ لا تَستَعجِلا أَن تَزَوَّدا وَأَن تَ...</td>\n",
       "      <td>الطويل</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>فَما لَبَثٌ يَوماً بِسابِقٍ مَغنَمٍ وَلا سُرعَ...</td>\n",
       "      <td>الطويل</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>وَإِن تُنظِراني اليَومَ أَقضِ لُبانَةً وَتَستَ...</td>\n",
       "      <td>الطويل</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>لَعَمرُكَ ما نَفسٌ بِجِدٍ رَشيدَةٍ تُؤامِرُني ...</td>\n",
       "      <td>الطويل</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>وَإِن ظَهَرَت مِنهُ قَوارِصُ جَمَّةٌ وَأَفرَعَ...</td>\n",
       "      <td>الطويل</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Bayt_Text    Bahr\n",
       "0  خَليلَيَّ لا تَستَعجِلا أَن تَزَوَّدا وَأَن تَ...  الطويل\n",
       "1  فَما لَبَثٌ يَوماً بِسابِقٍ مَغنَمٍ وَلا سُرعَ...  الطويل\n",
       "2  وَإِن تُنظِراني اليَومَ أَقضِ لُبانَةً وَتَستَ...  الطويل\n",
       "3  لَعَمرُكَ ما نَفسٌ بِجِدٍ رَشيدَةٍ تُؤامِرُني ...  الطويل\n",
       "4  وَإِن ظَهَرَت مِنهُ قَوارِصُ جَمَّةٌ وَأَفرَعَ...  الطويل"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eliminated_filtered_data = input_data.loc[input_data['Bahr'].isin(elminated_classic_bohor)]\n",
    "eliminated_filtered_data['Bayt_Text'] = eliminated_filtered_data['Bayt_Text'].apply(pyarabic.araby.strip_tatweel)\n",
    "eliminated_filtered_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strip Tatweel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mostafaalaa/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "filtered_data['Bayt_Text'] = filtered_data['Bayt_Text'].apply(pyarabic.araby.strip_tatweel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paths created\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    os.makedirs(\"../data/Encoded/8bits/WithoutTashkeel/Eliminated/\")\n",
    "    os.makedirs(\"../data/Encoded/8bits/WithoutTashkeel/Full_Data/\")\n",
    "    os.makedirs(\"../data/Encoded/8bits/WithTashkeel/Eliminated/\")\n",
    "    os.makedirs(\"../data/Encoded/8bits/WithTashkeel/Full_Data/\")\n",
    "except OSError as e:\n",
    "    if e.errno != errno.EEXIST:\n",
    "        print(\"Can't create file for checkpoints or for logs please check \")\n",
    "        raise\n",
    "print(\"Paths created\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encode Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving preprocessors....\n"
     ]
    }
   ],
   "source": [
    "full_data_label_encoder = LabelEncoder()\n",
    "full_data_integer_encoded = full_data_label_encoder.fit_transform(list(full_filtered_data[\"Bahr\"]))\n",
    "# binary encode\n",
    "full_data_onehot_encoder = OneHotEncoder(sparse=False)\n",
    "full_data_integer_encoded = full_data_integer_encoded.reshape(len(full_data_integer_encoded), 1)\n",
    "full_data_bohor_encoded = full_data_onehot_encoder.fit_transform(full_data_integer_encoded)\n",
    "save_h5('../data/Encoded/8bits/WithoutTashkeel/Full_Data/full_date_Y_Meters.h5', 'Y', full_data_bohor_encoded)\n",
    "save_h5('../data/Encoded/8bits/WithTashkeel/Full_Data/full_date_Y_Meters.h5', 'Y', full_data_bohor_encoded)\n",
    "#saving with pickle: https://stackoverflow.com/questions/11218477/how-can-i-use-pickle-to-save-a-dict\n",
    "print('saving preprocessors....')\n",
    "with open(\"../encoders_full_dat.pickle\", 'wb') as pre_file:\n",
    "    pickle.dump(full_data_label_encoder, pre_file, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "print('saved ....')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mostafaalaa/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['البسيط'], dtype='<U8')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print('loading saved encoders from %s'%(encoders_file_name))\n",
    "with open(\"../encoders_full_dat.pickle\", 'rb') as f:\n",
    "    encoders = pickle.load(f)\n",
    "##testing \n",
    "inverted = encoders.inverse_transform([argmax(full_filtered_data[\"Bahr\"][1,])])\n",
    "inverted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving preprocessors....\n"
     ]
    }
   ],
   "source": [
    "eliminated_data_label_encoder = LabelEncoder()\n",
    "eliminated_data_integer_encoded = eliminated_data_label_encoder.fit_transform(list(full_filtered_data[\"Bahr\"]))\n",
    "# binary encode\n",
    "eliminated_data_onehot_encoder = OneHotEncoder(sparse=False)\n",
    "eliminated_data_integer_encoded = eliminated_data_integer_encoded.reshape(len(eliminated_data_integer_encoded), 1)\n",
    "eliminated_data_bohor_encoded = eliminated_data_onehot_encoder.fit_transform(eliminated_data_integer_encoded)\n",
    "save_h5('../data/Encoded/8bits/WithoutTashkeel/Eliminated/Eliminated_data_Y_Meters.h5', 'Y', eliminated_data_bohor_encoded)\n",
    "save_h5('../data/Encoded/8bits/WithTashkeel/Eliminated/Eliminated_data_Y_Meters.h5', 'Y', eliminated_data_bohor_encoded)\n",
    "#saving with pickle: https://stackoverflow.com/questions/11218477/how-can-i-use-pickle-to-save-a-dict\n",
    "print('saving preprocessors....')\n",
    "with open(\"../encoders_eliminated_data.pickle\", 'wb') as pre_file:\n",
    "    pickle.dump(eliminated_data_bohor_encoded, pre_file, protocol=pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Omar Code for data cleansing in case Tashkeel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import sys\n",
    "import helpers\n",
    "from pyarabic.araby import strip_tatweel\n",
    "sys.path.append('.') # path of arabic file\n",
    "import arabic \n",
    "vectoriz_function = helpers.string_with_tashkeel_vectorizer\n",
    "counter = 0\n",
    "\n",
    "def separate_token_with_dicrites(token):\n",
    "    \"\"\"gets a token(string) with taskeel, and returns a list of strings,\n",
    "    each string in the list represents each character in the token with its own\n",
    "    tashkeel.\n",
    "    Args:\n",
    "        token (str): string represents a word or aya or sura\n",
    "    Returns:\n",
    "        [str]: a list contains the token characters with their tashkeel.\n",
    "    \"\"\"\n",
    "    token_without_tatweel = strip_tatweel(token)\n",
    "    hroof_with_tashkeel = []\n",
    "    for index,i in enumerate(token):\n",
    "        if(((token[index] in (arabic.alphabet or arabic.alefat or arabic.hamzat\n",
    ")) or token[index] is ' ' or  token[index] is \"\\n\" )):\n",
    "            k = index\n",
    "            harf_with_taskeel = token[index]\n",
    "            while((k+1) != len(token) and (token[k+1] in (arabic.tashkeel or \n",
    "            arabic.harakat or arabic.shortharakat or arabic.tanwin))):\n",
    "                harf_with_taskeel =harf_with_taskeel+\"\"+token[k+1]\n",
    "                k = k + 1\n",
    "            index = k\n",
    "            hroof_with_tashkeel.append(harf_with_taskeel)\n",
    "    return hroof_with_tashkeel\n",
    "\n",
    "\n",
    "def apply_cleaning(s):\n",
    "    global counter\n",
    "    try:\n",
    "        global vectoriz_function\n",
    "        vectoriz_function(s)\n",
    "        #print(counter)\n",
    "        counter+=1\n",
    "        return s\n",
    "    except:\n",
    "        s = solve_conflect(s)\n",
    "        #print(counter)\n",
    "        counter+=1\n",
    "        return s\n",
    "        #helpers.string_with_tashkeel_vectorizer(s)\n",
    "        \n",
    "\n",
    "def clean_fun(s):\n",
    "    if \" \" in s:\n",
    "        return \" \"\n",
    "    \n",
    "    non_remove = arabic.fatha+\"|\"+arabic.damma+\"|\"+arabic.kasra+\"|\"+arabic.sukun\n",
    "    remove = arabic.dammatan+\"|\"+arabic.fathatan+\"|\"+arabic.kasratan\n",
    "    tashkiel  = re.compile(r'('\"(\"+non_remove+\")\"+arabic.shadda+\")\")\n",
    "    tanwine  =  re.compile(r'('\"(\"+remove+\")\"+arabic.shadda+\")\")\n",
    "    tanwine_  =  re.compile(r'('+arabic.shadda+\"(\"+remove+\")\"+\")\")\n",
    "    spaces_w_tshkieel = re.compile(r'( ('+\"|\".join(arabic.tashkeel)+'))')\n",
    "    tanwine_2 = re.compile(r'(('+non_remove+')('+remove+')'')')\n",
    "    tow_tashkeel = re.compile(r'(('+non_remove+')('+non_remove+')'')')\n",
    "    tow_tashkeel_ = re.compile(r'(('+remove+')('+remove+')'')')\n",
    "    \n",
    "    lis=list(s)\n",
    "    for m in tashkiel.finditer(s):\n",
    "        lis[m.start()] , lis[m.start()+1] = lis[m.start()+1] , lis[m.start()]\n",
    "    for m in tanwine_.finditer(s):\n",
    "        del lis[m.start()]\n",
    "    for m in tanwine.finditer(s):\n",
    "        del lis[m.start()] \n",
    "    for m in tow_tashkeel.finditer(s):\n",
    "        del lis[m.start()]\n",
    "    for m in tow_tashkeel_.finditer(s):\n",
    "        del lis[m.start()]\n",
    "    for m in spaces_w_tshkieel.finditer(s):\n",
    "        del lis[m.start()+1]\n",
    "    for m in tanwine_2.finditer(s):\n",
    "        del lis[m.start()+1]\n",
    "    return \"\".join(lis)\n",
    "\n",
    "\n",
    "def solve_conflect(s):\n",
    "    return \"\".join([clean_fun(c) for c in separate_token_with_dicrites(s)])\n",
    "\n",
    "\n",
    "def Clean_data(data_frame,verse_column_name='Bayt_Text'):\n",
    "    our_alphabets = \"\".join(arabic.alphabet) + \"\".join(arabic.tashkeel)+\" \"\n",
    "    our_alphabets = \"\".join(our_alphabets)\n",
    "    data_frame[verse_column_name]    = data_frame[verse_column_name] .apply(lambda x: re.sub(r'[^'+our_alphabets+']','',str(x))).apply(lambda x: re.sub(r'  *',\" \",x)).apply(lambda x: re.sub(r'ّ+', 'ّ', x)).apply(lambda x: x.strip())\n",
    "    data_frame[verse_column_name] = data_frame[verse_column_name].apply(apply_cleaning)\n",
    "    return data_frame\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mostafaalaa/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:91: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/mostafaalaa/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1691671,)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_cleaned_data_with_tashkeel = Clean_data(filtered_data,'Bayt_Text')\n",
    "data_with_Tashkeel_cleaned = cleaned_data_with_tashkeel['Bayt_Text']\n",
    "\n",
    "\n",
    "data_with_Tashkeel_cleaned.shape\n",
    "#data_with_Tashkeel_cleaned.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maximum_bayt_len = np.max((data_with_Tashkeel_cleaned.apply(separate_token_with_dicrites).apply(len)))\n",
    "maximum_bayt_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encode Bayt Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoded_byot = data_with_Tashkeel_cleaned.apply(lambda x: helpers.string_with_tashkeel_vectorizer(x, maximum_bayt_len))\n",
    "encoded_byot = data_with_Tashkeel_cleaned.apply(lambda x: helpers.string_with_tashkeel_vectorizer_OneHot(x, maximum_bayt_len))\n",
    "len(encoded_byot[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(encoded_byot[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshaping the heck!!\n",
    "reshaped_data_matrix_with_tashkeel = np.stack(encoded_byot,axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Encoding Bayt Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save('full_data_matrix_with_tashkeel_onehotEncoding.h5', 'X', reshaped_data_matrix_with_tashkeel) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
