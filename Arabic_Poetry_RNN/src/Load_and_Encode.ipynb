{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mostafaalaa/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import arabic\n",
    "import pyarabic\n",
    "import helpers\n",
    "from helpers import Clean_data,separate_token_with_dicrites\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from numpy import array, argmax\n",
    "import numpy as np\n",
    "import os,errno,re,sys\n",
    "import pickle\n",
    "from itertools import product \n",
    "from pyarabic.araby import strip_tashkeel, strip_tatweel\n",
    "import h5py\n",
    "##########################\n",
    "\n",
    "input_data_path = \"../data/Almoso3a_Alshe3rya/data/All_ksaied.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_h5(nameOfFile,nameOfDataset,dataVar):\n",
    "    h5f = h5py.File(nameOfFile, 'w')\n",
    "    h5f.create_dataset(nameOfDataset, data=dataVar)\n",
    "    h5f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paths created\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    os.makedirs(\"../data/Encoded/8bits/WithoutTashkeel/Eliminated/\")\n",
    "    os.makedirs(\"../data/Encoded/8bits/WithoutTashkeel/Full_Data/\")\n",
    "    os.makedirs(\"../data/Encoded/8bits/WithTashkeel/Eliminated/\")\n",
    "    os.makedirs(\"../data/Encoded/8bits/WithTashkeel/Full_Data/\")\n",
    "except OSError as e:\n",
    "    if e.errno != errno.EEXIST:\n",
    "        print(\"Can't create file for checkpoints or for logs please check \")\n",
    "        raise\n",
    "print(\"Paths created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mostafaalaa/anaconda3/lib/python3.6/site-packages/numpy/lib/arraysetops.py:472: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1831770 entries, 0 to 1835252\n",
      "Data columns (total 8 columns):\n",
      "العصر           object\n",
      "الشاعر          object\n",
      "الديوان         object\n",
      "القافية         object\n",
      "البحر           object\n",
      "الشطر الايسر    object\n",
      "الشطر الايمن    object\n",
      "البيت           object\n",
      "dtypes: object(8)\n",
      "memory usage: 1.8 GB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1831770, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data = pd.read_csv(input_data_path, index_col=0)\n",
    "input_data.info(memory_usage='deep')\n",
    "bahr = 'Bahr'\n",
    "bayt = 'Bayt_Text'\n",
    "#input_data  = input_data[[bayt, bahr]]\n",
    "bahr = 'البحر'\n",
    "bayt = 'البيت'\n",
    "input_data  = input_data[[bayt, bahr]]\n",
    "input_data.columns = ['Bayt_Text','Bahr']\n",
    "our_alphabets = \"\".join(arabic.alphabet) + \"\".join(arabic.tashkeel)+\" \"\n",
    "our_alphabets = \"\".join(our_alphabets)\n",
    "input_data['Bayt_Text'] = input_data['Bayt_Text'].apply(lambda x: re.sub(r'[^'+our_alphabets+']','',str(x))).apply(lambda x: re.sub(r'  *',\" \",x)).apply(lambda x: re.sub(r'ّ+', 'ّ', x)).apply(lambda x: x.strip())\n",
    "input_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "الطويل          405378\n",
       "الكامل          363486\n",
       "البسيط          239974\n",
       "الخفيف          156049\n",
       "الوافر          140560\n",
       "الرجز           117572\n",
       "&nbsp;           92334\n",
       "الرمل            79015\n",
       "المتقارب         63818\n",
       "السريع           58084\n",
       "موشح             30060\n",
       "المنسرح          28357\n",
       "المجتث           17884\n",
       "المديد            7829\n",
       "الهزج             7541\n",
       "عامي              7074\n",
       "المتدارك          5037\n",
       "شعر التفعيلة      3232\n",
       "الدوبيت           2713\n",
       "شعر حر            2135\n",
       "المواليا          1644\n",
       "السلسلة            907\n",
       "المقتضب            799\n",
       "المضارع            288\n",
       "Name: Bahr, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data.iloc[:, 1].value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Filteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['الوافر',\n",
       " 'المنسرح',\n",
       " 'المجتث',\n",
       " 'المتقارب',\n",
       " 'الكامل',\n",
       " 'الطويل',\n",
       " 'السريع',\n",
       " 'الرمل',\n",
       " 'الرجز',\n",
       " 'الخفيف',\n",
       " 'البسيط']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elminated_classic_bohor = ['الوافر', 'المنسرح','المجتث', 'المتقارب', 'الكامل', 'الطويل', 'السريع', 'الرمل',\n",
    "                         'الرجز', 'الخفيف', 'البسيط']\n",
    "\n",
    "elminated_classic_bohor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['الوافر',\n",
       " 'المنسرح',\n",
       " 'المديد',\n",
       " 'المجتث',\n",
       " 'المتقارب',\n",
       " 'الكامل',\n",
       " 'الطويل',\n",
       " 'السريع',\n",
       " 'الرمل',\n",
       " 'الرجز',\n",
       " 'الخفيف',\n",
       " 'البسيط',\n",
       " 'المقتضب',\n",
       " 'الهزج',\n",
       " 'المضارع',\n",
       " 'المتدارك']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_bohor_classes = ['الوافر', 'المنسرح', 'المديد', 'المجتث', 'المتقارب', 'الكامل', 'الطويل', 'السريع', 'الرمل',\n",
    "                         'الرجز', 'الخفيف', 'البسيط', 'المقتضب', 'الهزج', 'المضارع', 'المتدارك']\n",
    "full_bohor_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mostafaalaa/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bayt_Text</th>\n",
       "      <th>Bahr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>خَليلَيَّ لا تَستَعجِلا أَن تَزَوَّدا وَأَن تَ...</td>\n",
       "      <td>الطويل</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>فَما لَبَثٌ يَوماً بِسابِقٍ مَغنَمٍ وَلا سُرعَ...</td>\n",
       "      <td>الطويل</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>وَإِن تُنظِراني اليَومَ أَقضِ لُبانَةً وَتَستَ...</td>\n",
       "      <td>الطويل</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>لَعَمرُكَ ما نَفسٌ بِجِدٍ رَشيدَةٍ تُؤامِرُني ...</td>\n",
       "      <td>الطويل</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>وَإِن ظَهَرَت مِنهُ قَوارِصُ جَمَّةٌ وَأَفرَعَ...</td>\n",
       "      <td>الطويل</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Bayt_Text    Bahr\n",
       "0  خَليلَيَّ لا تَستَعجِلا أَن تَزَوَّدا وَأَن تَ...  الطويل\n",
       "1  فَما لَبَثٌ يَوماً بِسابِقٍ مَغنَمٍ وَلا سُرعَ...  الطويل\n",
       "2  وَإِن تُنظِراني اليَومَ أَقضِ لُبانَةً وَتَستَ...  الطويل\n",
       "3  لَعَمرُكَ ما نَفسٌ بِجِدٍ رَشيدَةٍ تُؤامِرُني ...  الطويل\n",
       "4  وَإِن ظَهَرَت مِنهُ قَوارِصُ جَمَّةٌ وَأَفرَعَ...  الطويل"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_filtered_data = input_data.loc[input_data['Bahr'].isin(full_bohor_classes)]\n",
    "full_filtered_data['Bayt_Text'] = full_filtered_data['Bayt_Text'].apply(pyarabic.araby.strip_tatweel)\n",
    "full_filtered_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mostafaalaa/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bayt_Text</th>\n",
       "      <th>Bahr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>خَليلَيَّ لا تَستَعجِلا أَن تَزَوَّدا وَأَن تَ...</td>\n",
       "      <td>الطويل</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>فَما لَبَثٌ يَوماً بِسابِقٍ مَغنَمٍ وَلا سُرعَ...</td>\n",
       "      <td>الطويل</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>وَإِن تُنظِراني اليَومَ أَقضِ لُبانَةً وَتَستَ...</td>\n",
       "      <td>الطويل</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>لَعَمرُكَ ما نَفسٌ بِجِدٍ رَشيدَةٍ تُؤامِرُني ...</td>\n",
       "      <td>الطويل</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>وَإِن ظَهَرَت مِنهُ قَوارِصُ جَمَّةٌ وَأَفرَعَ...</td>\n",
       "      <td>الطويل</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Bayt_Text    Bahr\n",
       "0  خَليلَيَّ لا تَستَعجِلا أَن تَزَوَّدا وَأَن تَ...  الطويل\n",
       "1  فَما لَبَثٌ يَوماً بِسابِقٍ مَغنَمٍ وَلا سُرعَ...  الطويل\n",
       "2  وَإِن تُنظِراني اليَومَ أَقضِ لُبانَةً وَتَستَ...  الطويل\n",
       "3  لَعَمرُكَ ما نَفسٌ بِجِدٍ رَشيدَةٍ تُؤامِرُني ...  الطويل\n",
       "4  وَإِن ظَهَرَت مِنهُ قَوارِصُ جَمَّةٌ وَأَفرَعَ...  الطويل"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eliminated_filtered_data = input_data.loc[input_data['Bahr'].isin(elminated_classic_bohor)]\n",
    "eliminated_filtered_data['Bayt_Text'] = eliminated_filtered_data['Bayt_Text'].apply(pyarabic.araby.strip_tatweel)\n",
    "eliminated_filtered_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encode Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving preprocessors....\n",
      "saved ....\n"
     ]
    }
   ],
   "source": [
    "full_data_label_encoder = LabelEncoder()\n",
    "full_data_integer_encoded = full_data_label_encoder.fit_transform(list(full_filtered_data[\"Bahr\"]))\n",
    "# binary encode\n",
    "full_data_onehot_encoder = OneHotEncoder(sparse=False)\n",
    "full_data_integer_encoded = full_data_integer_encoded.reshape(len(full_data_integer_encoded), 1)\n",
    "full_data_bohor_encoded = full_data_onehot_encoder.fit_transform(full_data_integer_encoded)\n",
    "save_h5('../data/Encoded/8bits/WithoutTashkeel/Full_Data/full_data_Y_Meters.h5', 'Y', full_data_bohor_encoded)\n",
    "save_h5('../data/Encoded/8bits/WithTashkeel/Full_Data/full_data_Y_Meters.h5', 'Y', full_data_bohor_encoded)\n",
    "#saving with pickle: https://stackoverflow.com/questions/11218477/how-can-i-use-pickle-to-save-a-dict\n",
    "print('saving preprocessors....')\n",
    "with open(\"../encoders_full_dat.pickle\", 'wb') as pre_file:\n",
    "    pickle.dump(full_data_label_encoder, pre_file, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "print('saved ....')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mostafaalaa/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['البسيط'], dtype='<U8')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### testing\n",
    "#print('loading saved encoders from %s'%(encoders_file_name))\n",
    "with open(\"../encoders_full_dat.pickle\", 'rb') as f:\n",
    "    encoders = pickle.load(f)\n",
    "##testing \n",
    "inverted = encoders.inverse_transform([argmax(full_filtered_data[\"Bahr\"][1,])])\n",
    "inverted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving preprocessors....\n",
      "saved ...\n"
     ]
    }
   ],
   "source": [
    "eliminated_data_label_encoder = LabelEncoder()\n",
    "eliminated_data_integer_encoded = eliminated_data_label_encoder.fit_transform(list(eliminated_filtered_data[\"Bahr\"]))\n",
    "# binary encode\n",
    "eliminated_data_onehot_encoder = OneHotEncoder(sparse=False)\n",
    "eliminated_data_integer_encoded = eliminated_data_integer_encoded.reshape(len(eliminated_data_integer_encoded), 1)\n",
    "eliminated_data_bohor_encoded = eliminated_data_onehot_encoder.fit_transform(eliminated_data_integer_encoded)\n",
    "save_h5('../data/Encoded/8bits/WithoutTashkeel/Eliminated/Eliminated_data_Y_Meters.h5', 'Y', eliminated_data_bohor_encoded)\n",
    "save_h5('../data/Encoded/8bits/WithTashkeel/Eliminated/Eliminated_data_Y_Meters.h5', 'Y', eliminated_data_bohor_encoded)\n",
    "#saving with pickle: https://stackoverflow.com/questions/11218477/how-can-i-use-pickle-to-save-a-dict\n",
    "print('saving preprocessors....')\n",
    "with open(\"../encoders_eliminated_data.pickle\", 'wb') as pre_file:\n",
    "    pickle.dump(eliminated_data_bohor_encoded, pre_file, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "print('saved ...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean The Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WITH TASHKEEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FULL DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "'لٌ' is not in list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-0b65847e2458>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#full_filtered_data_with_tashkeel_cleaned = Clean_data(data_frame = full_filtered_data,max_bayt_len = bayt_len_full_withtashkeel,verse_column_name = 'Bayt_Text')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#print(\"full_cleaned_data_with_tashkeel cleaned ..\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mfull_cleaned_data_with_tashkeel_encoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfull_filtered_data_with_tashkeel_cleaned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBayt_Text\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mhelpers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_with_tashkeel_vectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbayt_len_full_withtashkeel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"full_cleaned_data_with_tashkeel_encoded encoded ..\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#save('../data/Encoded/8bits/WithTashkeel/Full_Data/full_data_matrix_with_tashkeel_8bitsEncoding.h5', 'X', reshaped_data_matrix_with_tashkeel)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[1;32m   2549\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2550\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masobject\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2551\u001b[0;31m                 \u001b[0mmapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2553\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/src/inference.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-0b65847e2458>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#full_filtered_data_with_tashkeel_cleaned = Clean_data(data_frame = full_filtered_data,max_bayt_len = bayt_len_full_withtashkeel,verse_column_name = 'Bayt_Text')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#print(\"full_cleaned_data_with_tashkeel cleaned ..\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mfull_cleaned_data_with_tashkeel_encoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfull_filtered_data_with_tashkeel_cleaned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBayt_Text\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mhelpers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_with_tashkeel_vectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbayt_len_full_withtashkeel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"full_cleaned_data_with_tashkeel_encoded encoded ..\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#save('../data/Encoded/8bits/WithTashkeel/Full_Data/full_data_matrix_with_tashkeel_8bitsEncoding.h5', 'X', reshaped_data_matrix_with_tashkeel)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/mostafaalaa/Main_Hard/Learning/Master/CombinedWorkspace/Python/DeepLearningMaster/ArabicPoetry/ArabicPoetry-1/Arabic_Poetry_RNN/src/helpers.py\u001b[0m in \u001b[0;36mstring_with_tashkeel_vectorizer\u001b[0;34m(string, padding_length)\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0mrepresentation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstring_clean\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marabic_alphabet_tashkeel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0mrepresentation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoding_combination_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: 'لٌ' is not in list"
     ]
    }
   ],
   "source": [
    "#bayt_len_full_withtashkeel = np.max((full_filtered_data.Bayt_Text.apply(separate_token_with_dicrites).apply(len)))\n",
    "#print(\"bayt_len_full_withtashkeel done..\")\n",
    "#full_filtered_data_with_tashkeel_cleaned = Clean_data(data_frame = full_filtered_data,max_bayt_len = bayt_len_full_withtashkeel,verse_column_name = 'Bayt_Text')\n",
    "#print(\"full_cleaned_data_with_tashkeel cleaned ..\")\n",
    "full_cleaned_data_with_tashkeel_encoded = full_filtered_data_with_tashkeel_cleaned.Bayt_Text.apply(lambda x: helpers.string_with_tashkeel_vectorizer(x, bayt_len_full_withtashkeel))\n",
    "print(\"full_cleaned_data_with_tashkeel_encoded encoded ..\")\n",
    "#save('../data/Encoded/8bits/WithTashkeel/Full_Data/full_data_matrix_with_tashkeel_8bitsEncoding.h5', 'X', reshaped_data_matrix_with_tashkeel) \n",
    "#print(\"full_cleaned_data_with_tashkeel_encoded saved ..\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ELIMINATED DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eliminated_cleaned_data_with_tashkeel = Clean_data(eliminated_filtered_data,'Bayt_Text')\n",
    "maximum_bayt_len_eliminated_withtashkeel = np.max((eliminated_cleaned_data_with_tashkeel.apply(separate_token_with_dicrites).apply(len)))\n",
    "eliminated_cleaned_data_with_tashkeel_encoded = eliminated_cleaned_data_with_tashkeel.apply(lambda x: helpers.string_with_tashkeel_vectorizer(x, maximum_bayt_len_eliminated_withtashkeel))\n",
    "eliminated_cleaned_data_with_tashkeel_encoded_stacked = np.stack(eliminated_cleaned_data_with_tashkeel_encoded,axis=0)\n",
    "save('full_data_matrix_with_tashkeel_onehotEncoding.h5', 'X', reshaped_data_matrix_with_tashkeel) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encode Bayt Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_byot = data_with_Tashkeel_cleaned.apply(lambda x: helpers.string_with_tashkeel_vectorizer(x, maximum_bayt_len))\n",
    "#encoded_byot = data_with_Tashkeel_cleaned.apply(lambda x: helpers.string_with_tashkeel_vectorizer_OneHot(x, maximum_bayt_len))\n",
    "len(encoded_byot[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(encoded_byot[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshaping the heck!!\n",
    "reshaped_data_matrix_with_tashkeel = np.stack(encoded_byot,axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Encoding Bayt Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save('full_data_matrix_with_tashkeel_onehotEncoding.h5', 'X', reshaped_data_matrix_with_tashkeel) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
