{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/moroclash/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import sys\n",
    "from sklearn.utils import shuffle\n",
    "import h5py\n",
    "import time\n",
    "import seaborn as ses\n",
    "\n",
    "from IPython import display\n",
    "import pylab as pl\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model of one-layer LSTM using tensorflow LSTM cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load X,Y Data from folder /Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def restore (nameOfFile,nameOfDataset):\n",
    "    h5f = h5py.File(nameOfFile,'r')\n",
    "    matrix = h5f[nameOfDataset][:]\n",
    "    h5f.close()\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = restore(\"Data/data_matrix_X.h5\",\"X\")\n",
    "Y = restore(\"Data/data_matrix_Y.h5\",\"Y\")\n",
    "\n",
    "x_train,x_test,y_train,y_test = train_test_split(X,Y,test_size=0.40,random_state=42)\n",
    "x_validate,x_test,y_validate,y_test = train_test_split(x_test,y_test,test_size=0.50,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(700, 83, 27)\n",
      "(700, 2)\n",
      "(234, 83, 27)\n",
      "(234, 2)\n",
      "(233, 83, 27)\n",
      "(233, 2)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)\n",
    "print(x_validate.shape)\n",
    "print(y_validate.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model tuning parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# size of input vector\n",
    "input_size = 27\n",
    "# nimber of hidden unit\n",
    "hidden_size = 80\n",
    "# number of output vector\n",
    "output_size = 2\n",
    "\n",
    "\n",
    "learn_rate = 0.001\n",
    "\n",
    "batch_size = 700\n",
    "epoch_number = 1200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LstmCell(object):\n",
    "    \n",
    "    def __init__(self,input_size , hidden_size , output_size):\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        \n",
    "        #weight of output layer\n",
    "        self.vo = tf.Variable(\n",
    "            tf.random_normal([self.hidden_size,output_size],\n",
    "                             mean=0,stddev=0.01,seed=1),name='vo')\n",
    "        self.bo = tf.Variable(\n",
    "            tf.ones([self.output_size]),name='bo')\n",
    "        \n",
    "        #define shape of input matrix  \n",
    "        self.inputs_matrix = tf.placeholder(\n",
    "            dtype=tf.float32 ,shape=[None,None,self.input_size],name='inputs_matrix')\n",
    "        \n",
    "    def get_outputs(self):\n",
    "        \"\"\"get all output for all states\n",
    "    \n",
    "        Returns:\n",
    "            all_outputs: output matrix for all state  \n",
    "\n",
    "        Note:\n",
    "            returned matrix size (state_numbers , batch_number , output_size )\n",
    "        \"\"\"\n",
    "        cell = tf.contrib.rnn.LSTMCell(self.hidden_size)\n",
    "        all_outputs , states = tf.nn.dynamic_rnn(cell, self.inputs_matrix, dtype=tf.float32)\n",
    "        all_outputs = tf.transpose(all_outputs, [1, 0, 2])\n",
    "        return all_outputs\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/moroclash/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:95: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    }
   ],
   "source": [
    "# define LstmCE class\n",
    "rnn = LstmCell(hidden_size=hidden_size,input_size=input_size,output_size=output_size)\n",
    "\n",
    "#get all outputs \n",
    "outputs = rnn.get_outputs()\n",
    "\n",
    "#get last state for batch\n",
    "last_output = tf.gather(outputs, x_train.shape[1] - 1)\n",
    "\n",
    "#apply softmax on all last states\n",
    "output = tf.nn.softmax(tf.matmul(last_output,rnn.vo)+rnn.bo)\n",
    "\n",
    "#define shape of y\n",
    "y = tf.placeholder(tf.float32,shape=[None,output_size])\n",
    "\n",
    "#compute Cost_function \n",
    "cross_entropy = -tf.reduce_sum(y * tf.log(tf.clip_by_value(output,1e-10,1.0)))/batch_size\n",
    "\n",
    "#use AdamOptmizer to reduece error\n",
    "optmizer_step = tf.train.AdamOptimizer().minimize(cross_entropy)\n",
    "\n",
    "#compute accuracy\n",
    "correct_prediction = tf.equal(tf.argmax(y,1),tf.argmax(output,1))\n",
    "accuracy = (tf.reduce_sum(tf.cast(correct_prediction,tf.float32)))*100\n",
    "\n",
    "# # compute error \n",
    "# mistakes = tf.not_equal(tf.argmax(target, 1), tf.argmax(prediction, 1))\n",
    "# error = tf.reduce_mean(tf.cast(mistakes, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/moroclash/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/tf_should_use.py:175: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.initialize_all_variables())\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.667142857142857\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "loss_fig=[]\n",
    "test_accuracy_fig=[]\n",
    "train_accuracy_fig=[]\n",
    "validate_accuracy_fig=[]\n",
    "epoch_fig=[]\n",
    "\n",
    "best_validate_accuracy =0\n",
    "bvc_test_accuracy=0\n",
    "bvc_train_accuracy=0\n",
    "improve_count = 0\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(1):\n",
    "    start = 0\n",
    "    end = batch_size\n",
    "    batchs_num = int(X.shape[0]/batch_size)\n",
    "    print(X.shape[0]/batch_size)\n",
    "#     for i in range(batchs_num):\n",
    "#         X = x_train[start:end]\n",
    "#         Y = y_train[start:end]\n",
    "#         start=end\n",
    "#         end=end+batch_size\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Info\n",
    "\n",
    " * input layer :: 27\n",
    " * hidden layer units :: 160\n",
    " * output layer :: 2\n",
    " \n",
    " * one-layer tf LSTM\n",
    " * epoch : 1200\n",
    " * batch size : 700  \"all training set\"\n",
    " \n",
    " \n",
    "  after 1200 epoch :    there is over fiting\n",
    " * Train-Accuracy:      96.7142857143 \n",
    " * Validate-Accuracy:      66.9527896996 \n",
    " * test-Accuracy:      69.2307692308\n",
    " \n",
    " \n",
    " #### note : we save pramaters after reach to the best Validate accurecy aftert 12 improvement \n",
    " ####            best Validate accuracy : 79.399%\n",
    " ####  we use Gradient Clipping to reduce the effect of vanishing problem "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get all outputs of test set\n",
    "test_outputs = rnn.get_outputs()\n",
    "sess.run(test_outputs,feed_dict={rnn.inputs_matrix:x_test})\n",
    "#get last state of last time step\n",
    "last_test_output = test_outputs[-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#apply softmax on last_test_output\n",
    "y_predict = sess.run(tf.nn.softmax(last_test_output),feed_dict={rnn.inputs_matrix:x_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#compute accuracy\n",
    "correct_prediction = tf.equal(tf.argmax(y_predict,1),tf.argmax(y_test,1))\n",
    "accuracy = (tf.reduce_sum(tf.cast(correct_prediction,tf.float32))*100)/len(x_test)\n",
    "print(\"Accuracy of test set :: %s \"%(sess.run(accuracy)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num = 44\n",
    "print(y_test[num])\n",
    "print(y_predict[num])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrive pramaters from Pramaters folder and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "#define new graph\n",
    "new_graph = tf.Graph()\n",
    "#start new session called sess2\n",
    "with tf.Session(graph=new_graph) as sess2:  \n",
    "    #define new_rnn\n",
    "    new_rnn = LstmCell(hidden_size=hidden_size,input_size=input_size,output_size=output_size)\n",
    "    #get all outputs\n",
    "    predicted_outputs = new_rnn.get_outputs()\n",
    "    #initialize pramaters of new_rnn\n",
    "    sess2.run(tf.initialize_all_variables())\n",
    "    #define saver\n",
    "    saver = tf.train.Saver()\n",
    "    #get saved pramaters\n",
    "    tf.train.import_meta_graph('Pramaters/Model_4_using_TF_LSTM.meta')\n",
    "    #get last checkpoint\n",
    "    saver.restore(sess2,tf.train.latest_checkpoint('Pramaters/'))\n",
    "    #run graph\n",
    "    predicted_outputs = sess2.run(predicted_outputs,feed_dict={new_rnn.inputs_matrix:x_test})\n",
    "    #get last time step\n",
    "    last_test_output = predicted_outputs[-1]\n",
    "    #apply softmax layer\n",
    "    y_predict = sess2.run(tf.nn.softmax(last_test_output),feed_dict={new_rnn.inputs_matrix:x_test})\n",
    "    #compute accuracy of test set\n",
    "    correct_prediction = tf.equal(tf.argmax(y_predict,1),tf.argmax(y_test,1))\n",
    "    accuracy = (tf.reduce_sum(tf.cast(correct_prediction,tf.float32))*100)/len(x_test)\n",
    "    print(\"Accuracy of test set :: %s \"%(sess2.run(accuracy)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
