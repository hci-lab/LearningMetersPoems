{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import sys\n",
    "from sklearn.utils import shuffle\n",
    "import h5py\n",
    "import time\n",
    "import seaborn as ses\n",
    "\n",
    "from IPython import display\n",
    "import pylab as pl\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model of one layer GRU\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load X,Y Data from folder /Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def restore (nameOfFile,nameOfDataset):\n",
    "    h5f = h5py.File(nameOfFile,'r')\n",
    "    matrix = h5f[nameOfDataset][:]\n",
    "    h5f.close()\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = restore(\"Data/data_matrix_X.h5\",\"X\")\n",
    "Y = restore(\"Data/data_matrix_Y.h5\",\"Y\")\n",
    "\n",
    "x_train,x_test,y_train,y_test = train_test_split(X,Y,test_size=0.40,random_state=42)\n",
    "x_validate,x_test,y_validate,y_test = train_test_split(x_test,y_test,test_size=0.50,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(700, 83, 27)\n",
      "(700, 2)\n",
      "(234, 83, 27)\n",
      "(234, 2)\n",
      "(233, 83, 27)\n",
      "(233, 2)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)\n",
    "print(x_validate.shape)\n",
    "print(y_validate.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model tuning parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# size of input vector\n",
    "input_size = 27\n",
    "# nimber of hidden unit\n",
    "hidden_size = 160\n",
    "# number of output vector\n",
    "output_size = 2\n",
    "\n",
    "learn_rate = 0.001\n",
    "\n",
    "batch_size = 700\n",
    "epoch_number = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Design of RGU cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class GruCell(object):\n",
    "    \n",
    "    def __init__(self,input_size , hidden_size , output_size):\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        \n",
    "        #weight of input vector\n",
    "        self.ui = tf.Variable(\n",
    "            tf.random_normal([self.input_size,self.hidden_size],\n",
    "                             mean=0,stddev=0.01,seed=1),name='ui')\n",
    "        \n",
    "        #weight of rest gate\n",
    "        self.wr = tf.Variable(\n",
    "            tf.random_normal([self.input_size,self.hidden_size],\n",
    "                             mean=0,stddev=0.01,seed=1),name='wr')\n",
    "        self.br = tf.Variable(\n",
    "            tf.ones([self.hidden_size]),name='br')\n",
    "        \n",
    "        #weight of update gate\n",
    "        self.wz = tf.Variable(\n",
    "            tf.random_normal([self.input_size,self.hidden_size],\n",
    "                             mean=0,stddev=0.01,seed=1),name='wz')\n",
    "        self.bz = tf.Variable(\n",
    "            tf.ones([self.hidden_size]),name='bz')\n",
    "\n",
    "        #weight of hidden layer\n",
    "        self.wh = tf.Variable(\n",
    "            tf.random_normal([self.hidden_size,self.hidden_size],\n",
    "                             mean=0,stddev=0.01,seed=1),name='wh')\n",
    "        \n",
    "        #weight of output layer\n",
    "        self.vo = tf.Variable(\n",
    "            tf.random_normal([self.hidden_size,output_size],\n",
    "                             mean=0,stddev=0.01,seed=1),name='vo')\n",
    "        self.bo = tf.Variable(\n",
    "            tf.ones([self.output_size]),name='bo')\n",
    "        \n",
    "        #define shape of input matrix  \n",
    "        \n",
    "        self.inputs_matrix = tf.placeholder(\n",
    "            dtype=tf.float32 ,shape=[None,None,self.input_size],name='inputs_matrix')\n",
    "        \n",
    "        #prepare input matrix to feed model \n",
    "        # it will make matrix as [m,t,n] --> [t,m,n]\n",
    "        # t : number of time\n",
    "        # n : length of input vector\n",
    "        # m : number of sentences\n",
    "        self.feed_marix = tf.transpose(\n",
    "            self.inputs_matrix,perm=[1,0,2],name='feed_marix')\n",
    "        \n",
    "        #prepare initial state as matrix of zerose (batch_size,hidden_size)\n",
    "        self.initial_state = tf.matmul(\n",
    "            self.feed_marix[0],\n",
    "            tf.zeros([self.input_size,self.hidden_size]),name='initial_state')\n",
    "        \n",
    "        \n",
    "    def gru(self, previous_hidden_state, x):\n",
    "        \"\"\"gur cell that compute  curent state at time t using\n",
    "           previous state at t-1 and input vector x\n",
    "    \n",
    "        Args:\n",
    "            previous_hidden_state (matrix): previous_state at (t-1) .\n",
    "            x (vector): input vector of char.\n",
    "\n",
    "        Returns:\n",
    "            current_hidden_state: current state\n",
    "\n",
    "        Note:\n",
    "            returned matrix size (batch_number , hidden_unit_size)\n",
    "        \"\"\"\n",
    "        #compute update gate that update state_at_(t-1)\n",
    "        z= tf.sigmoid(tf.matmul(x,self.wz)+ self.bz)\n",
    "        #compute reset gate \n",
    "        r= tf.sigmoid(tf.matmul(x,self.wr)+ self.br)  \n",
    "        #compute internal memory\n",
    "        h_= tf.tanh(tf.matmul(x,self.ui) + tf.matmul(previous_hidden_state,self.wh)*r)\n",
    "        #compute current state\n",
    "        current_hidden_state = tf.multiply((1-z),h_) + tf.multiply(previous_hidden_state,z)\n",
    "        return current_hidden_state  \n",
    "        \n",
    "    def get_states(self):\n",
    "        \"\"\"get all state of batch_number example it accumulate \n",
    "           all states of one sentence matrix like :\n",
    "           S0 = initial_state + x0\n",
    "           S1 = S0 + x1\n",
    "           S2 = S1 + x2\n",
    "                .\n",
    "                .\n",
    "           Sn = Sn-1 + xn\n",
    "           \n",
    "           and for batch_number\n",
    "    \n",
    "        Returns:\n",
    "            all_stats: all state of m example\n",
    "\n",
    "        Note:\n",
    "            returned matrix size (number_time_steps ,batch_number , input_size )\n",
    "        \"\"\"\n",
    "        # apply gru function on all matrix of all batch like\n",
    "        #   state_0 =  gru(initial_state,feed_marix[0])\n",
    "        #   state_1 =  gru(state_0,feed_matrix[1])\n",
    "        all_stats = tf.scan(self.gru,self.feed_marix,self.initial_state,name=\"stats\")\n",
    "        return all_stats        \n",
    "        \n",
    "    def get_output(self,hidden_stat):\n",
    "        \"\"\"apply the hidden_state on RELU activation \n",
    "           function to compute output\n",
    "        \n",
    "        Args:\n",
    "            hidden_stat (matrix): state at time t\n",
    "        \n",
    "        Returns:\n",
    "            output: output matrix\n",
    "\n",
    "        Note:\n",
    "            returned matrix size (batch_number , output_size )\n",
    "        \"\"\"\n",
    "        output = tf.nn.relu(tf.matmul(hidden_stat,self.vo)+self.bo,name='output')\n",
    "        return output\n",
    "    \n",
    "        \n",
    "    def get_outputs(self):\n",
    "        \"\"\"get all output for all states\n",
    "    \n",
    "        Returns:\n",
    "            all_outputs: output matrix for all state  \n",
    "\n",
    "        Note:\n",
    "            returned matrix size (state_numbers , batch_number , output_size )\n",
    "        \"\"\"\n",
    "        #get all states for every time step \n",
    "        all_stats = self.get_states()\n",
    "        #compute output matrix for all states\n",
    "        all_outputs = tf.map_fn(self.get_output,all_stats,name='all_outputs')\n",
    "        return all_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define GruCell class\n",
    "rnn = GruCell(hidden_size=hidden_size,input_size=input_size,output_size=output_size)\n",
    "\n",
    "#get all outputs \n",
    "outputs = rnn.get_outputs()\n",
    "\n",
    "#get last state for batch\n",
    "last_output = outputs[-1]\n",
    "\n",
    "#apply softmax on all last states\n",
    "output = tf.nn.softmax(last_output)\n",
    "\n",
    "#define shape of y\n",
    "y = tf.placeholder(tf.float32,shape=[None,output_size])\n",
    "\n",
    "#compute Cost_function \n",
    "cross_entropy = -tf.reduce_sum(y * tf.log(output))/batch_size\n",
    "\n",
    "#use AdamOptmizer to reduece error\n",
    "optmizer_step = tf.train.AdamOptimizer(learning_rate=learn_rate).minimize(cross_entropy)\n",
    "\n",
    "#compute accuracy\n",
    "correct_prediction = tf.equal(tf.argmax(y,1),tf.argmax(output,1))\n",
    "accuracy = (tf.reduce_sum(tf.cast(correct_prediction,tf.float32)))*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/moroclash/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/tf_should_use.py:175: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.initialize_all_variables())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3AAAAFmCAYAAAAs+nh4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f13720ed128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Iteration:      1 \n",
      "               Loss:      69.2236959934 \n",
      "     Train-Accuracy:      54.7142857143 \n",
      "  Validate-Accuracy:      56.2231759657 \n",
      "      test-Accuracy:      50.8547008547 \n",
      "\n",
      "\n",
      "--- 0.15839500824610392 minute ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "loss_fig=[]\n",
    "test_accuracy_fig=[]\n",
    "train_accuracy_fig=[]\n",
    "validate_accuracy_fig=[]\n",
    "epoch_fig=[]\n",
    "\n",
    "def print_info():\n",
    "    pl.figure(figsize=(15,6))\n",
    "    pl.plot(epoch_fig,loss_fig,'b')\n",
    "    pl.plot(epoch_fig,train_accuracy_fig,'r')\n",
    "    pl.plot(epoch_fig,validate_accuracy_fig,'g')\n",
    "    pl.plot(epoch_fig,test_accuracy_fig,'y')\n",
    "    pl.show()\n",
    "\n",
    "    sys.stdout.flush()\n",
    "    print(\"\\r         Iteration:      %s \\n\" \n",
    "          \"               Loss:      %s \\n\"  \n",
    "          \"     Train-Accuracy:      %s \\n\"\n",
    "          \"  Validate-Accuracy:      %s \\n\"\n",
    "          \"      test-Accuracy:      %s \\n\"%(epoch,loss,train_accuracy,validate_acuuracy,test_acuuracy))\n",
    "    sys.stdout.flush()\n",
    "\n",
    "\n",
    "\n",
    "pl.ion() \n",
    "for epoch in range(2):\n",
    "    start = 0\n",
    "    end = batch_size\n",
    "    batchs_num = int(X.shape[0]/batch_size)\n",
    "    for i in range(batchs_num):\n",
    "        X = x_train[start:end]\n",
    "        Y = y_train[start:end]\n",
    "        start=end\n",
    "        end=end+batch_size\n",
    "        sess.run(optmizer_step,feed_dict={rnn.inputs_matrix:X,y:Y})\n",
    "    \n",
    "    loss = sess.run(cross_entropy,feed_dict={rnn.inputs_matrix:X,y:Y})*100\n",
    "    train_accuracy = sess.run(accuracy,feed_dict={rnn.inputs_matrix:x_train,y:y_train}) / len(x_train)\n",
    "    validate_acuuracy = sess.run(accuracy,feed_dict={rnn.inputs_matrix:x_validate,y:y_validate}) / len(x_validate)\n",
    "    test_acuuracy = sess.run(accuracy,feed_dict={rnn.inputs_matrix:x_test,y:y_test}) / len(x_test)\n",
    "\n",
    "    epoch_fig.append(epoch)\n",
    "    loss_fig.append(loss)\n",
    "    train_accuracy_fig.append(train_accuracy)\n",
    "    validate_accuracy_fig.append(validate_acuuracy)\n",
    "    test_accuracy_fig.append(test_acuuracy)\n",
    "    \n",
    "\n",
    "    print_info()\n",
    "    display.clear_output(wait=True)\n",
    "\n",
    "    \n",
    "print_info()\n",
    "print(\"\\n--- %s minute ---\" % ((time.time() - start_time)/60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get all outputs of test set\n",
    "test_outputs = rnn.get_outputs()\n",
    "sess.run(test_outputs,feed_dict={rnn.inputs_matrix:x_test})\n",
    "#get last state of last time step\n",
    "last_test_output = test_outputs[-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#apply softmax on last_test_output\n",
    "y_predict = sess.run(tf.nn.softmax(last_test_output),feed_dict={rnn.inputs_matrix:x_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of test set :: 50.8547 \n"
     ]
    }
   ],
   "source": [
    "#compute accuracy\n",
    "correct_prediction = tf.equal(tf.argmax(y_predict,1),tf.argmax(y_test,1))\n",
    "accuracy = (tf.reduce_sum(tf.cast(correct_prediction,tf.float32))*100)/len(x_test)\n",
    "print(\"Accuracy of test set :: %s \"%(sess.run(accuracy)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  1.]\n",
      "[ 0.49525711  0.50474292]\n"
     ]
    }
   ],
   "source": [
    "num = 10\n",
    "print(y_test[num])\n",
    "print(y_predict[num])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "At least two variables have the same name: wz",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-c388f12bca56>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msaver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSaver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Pramaters/Model_1_using_GRU'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/moroclash/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, var_list, reshape, sharded, max_to_keep, keep_checkpoint_every_n_hours, name, restore_sequentially, saver_def, builder, defer_build, allow_empty, write_version, pad_step_number, save_relative_paths, filename)\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdefer_build\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1140\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1141\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaver_def\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_saver_def\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/moroclash/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1170\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1171\u001b[0m           \u001b[0mrestore_sequentially\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_restore_sequentially\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1172\u001b[0;31m           filename=self._filename)\n\u001b[0m\u001b[1;32m   1173\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaver_def\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1174\u001b[0m       \u001b[0;31m# Since self._name is used as a name_scope by builder(), we are\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/moroclash/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, names_to_saveables, reshape, sharded, max_to_keep, keep_checkpoint_every_n_hours, name, restore_sequentially, filename)\u001b[0m\n\u001b[1;32m    668\u001b[0m         \u001b[0munique\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m     \"\"\"\n\u001b[0;32m--> 670\u001b[0;31m     \u001b[0msaveables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ValidateAndSliceInputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames_to_saveables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    671\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmax_to_keep\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m       \u001b[0mmax_to_keep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/moroclash/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36m_ValidateAndSliceInputs\u001b[0;34m(self, names_to_saveables)\u001b[0m\n\u001b[1;32m    553\u001b[0m     \"\"\"\n\u001b[1;32m    554\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames_to_saveables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m       \u001b[0mnames_to_saveables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBaseSaverBuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpListToDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames_to_saveables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    556\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m     \u001b[0msaveables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/moroclash/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36mOpListToDict\u001b[0;34m(op_list)\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnames_to_saveables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m           raise ValueError(\"At least two variables have the same name: %s\" %\n\u001b[0;32m--> 533\u001b[0;31m                            name)\n\u001b[0m\u001b[1;32m    534\u001b[0m         \u001b[0mnames_to_saveables\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m       \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: At least two variables have the same name: wz"
     ]
    }
   ],
   "source": [
    "saver = tf.train.Saver()\n",
    "saver.save(sess, 'Pramaters/Model_1_using_GRU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
