{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Modles to English Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Add option to read from padded or to rerun it again.\n",
    "# =============================================================================\n",
    "import numpy as np\n",
    "from numpy import array\n",
    "from numpy import argmax\n",
    "import pandas as pd\n",
    "import os,errno\n",
    "from time import time\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing import sequence\n",
    "from keras.layers import Dropout,LSTM, Lambda,Bidirectional,GRU,Dense\n",
    "from keras.callbacks import ModelCheckpoint,TensorBoard#,TimeDistributed\n",
    "#from keras.models import load_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import backend as K\n",
    "import sys\n",
    "from preprocessing import restore\n",
    "import tensorflow as tf\n",
    "import random as rn\n",
    "\n",
    "# =============================================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# =======================Program Parameters====================================\n",
    "load_weights_flag = 1\n",
    "# 0-> last wait | 1 max val_acc\n",
    "last_or_max_val_acc = 0\n",
    "\n",
    "Experiement_Name = 'Experiment_test'\n",
    "layer_number = 3\n",
    "#if u need one number for all layers add number alone\n",
    "n_units = [200]\n",
    "# 1->LSTM  , 2->GRU , 3->Bi-LSTM \n",
    "cell_mode = 2\n",
    "drop_out_rate = 0.1\n",
    "test_size_param=0.1\n",
    "validation_split_param = 0.1\n",
    "batch_size_param = 64\n",
    "# 0 -> for test mode , 1 -> for train mode\n",
    "learning_mode = 1\n",
    "\n",
    "epochs_param = 5\n",
    "#num of epoch should be wait when monitor don't change\n",
    "earlystopping_patience=-1  \n",
    "\n",
    "seed = 7\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "np.random.seed(seed)\n",
    "rn.seed(seed)\n",
    "\n",
    "\n",
    "# =========================Functions ==========================================\n",
    "class LossHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.losses = []\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        self.losses.append(logs.get('loss'))\n",
    "# ============================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#===============================Concatinated Variables ========================\n",
    "checkpoints_path =\"../Experiement/checkpoints/\"+Experiement_Name+\"/\"\n",
    "check_points_file_path = checkpoints_path+ \"/weights-improvement-{epoch:02d}-{val_acc:.2f}.hdf5\"\n",
    "board_log_dir=\"../Experiement/logs/\"+Experiement_Name+\"/\"#+.format(time())\n",
    "\n",
    "try:\n",
    "    os.makedirs(board_log_dir)\n",
    "    os.makedirs(checkpoints_path)\n",
    "except OSError as e:\n",
    "    if e.errno != errno.EEXIST:\n",
    "        print(\"Can't create file for checkpoints or for logs please check \")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# =========================Data Loading========================================\n",
    "X = restore(\"../data/data_matrix_X_binary_encoding.h5\",\"X\")\n",
    "Y = restore(\"../data/data_matrix_Y_one_hot_encoding.h5\",\"Y\")\n",
    "X =X[0:100]\n",
    "Y =Y[0:100]\n",
    "max_Bayt_length=X.shape[1]\n",
    "char_dimension=X.shape[2]\n",
    "numbber_of_bohor=Y.shape[1]\n",
    "# =============================================================================\n",
    "\n",
    "\n",
    "# ==============================Split Data=====================================\n",
    "X_train, X_test, Y_train, Y_test=train_test_split(X, #bayts\n",
    "                                                  Y, #classes\n",
    "                                                  test_size=test_size_param, \n",
    "                                                  random_state=0)\n",
    "# ============================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90, 93, 5)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# =========================RNN models ================================\n",
    "# create model\n",
    "K.set_learning_phase(learning_mode) #set learning phase\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# add layers\n",
    "for n in range(layer_number):\n",
    "    if len(n_units)==1 and layer_number>1:\n",
    "        i=0\n",
    "    else:\n",
    "        if len(n_units)>=1 and len(n_units) != layer_number:\n",
    "            sys.exit(\"pleas make length of n_units == layer_number or add only one element in n_units \")\n",
    "        i=n\n",
    "    # check if LSTM \n",
    "    if cell_mode==1:\n",
    "        #check if first layer to add input_shape\n",
    "        if n==0:\n",
    "            # if NN as only one layer so shuld remove retun_sequences\n",
    "            if layer_number == 1:\n",
    "                model.add(LSTM(n_units[i],input_shape=(max_Bayt_length,char_dimension)))\n",
    "            # if NN has many layers so should add return_sequences\n",
    "            else:\n",
    "                model.add(LSTM(n_units[i], return_sequences=True,input_shape=(max_Bayt_length,char_dimension)))\n",
    "        # if it's not the first layer\n",
    "        else:\n",
    "            #check if last layer\n",
    "            if layer_number-1 == n:\n",
    "                model.add(LSTM(n_units[i]))\n",
    "            else:\n",
    "                model.add(LSTM(n_units[i], return_sequences=True))\n",
    "\n",
    "    #check if GRU    \n",
    "    elif cell_mode==2:\n",
    "\n",
    "        #check if first layer to add input_shape\n",
    "        if n==0:\n",
    "            if layer_number  == 1:\n",
    "            # if NN as only one layer so shuld remove retun_sequences\n",
    "                model.add(GRU(n_units[i],input_shape=(max_Bayt_length,char_dimension)))\n",
    "            # if NN has many layers so should add return_sequences\n",
    "            else:\n",
    "                model.add(GRU(n_units[i], return_sequences=True,input_shape=(max_Bayt_length,char_dimension)))\n",
    "        # if it's not the first layer\n",
    "        else:\n",
    "            #check if last layer\n",
    "            if layer_number-1 == n:\n",
    "                model.add(GRU(n_units[i]))\n",
    "            else:\n",
    "                model.add(GRU(n_units[i], return_sequences=True))        \n",
    "    #check if Bi-LSTM\n",
    "    else:\n",
    "        #check if first layer to add input_shape\n",
    "        if n==0:\n",
    "            # if NN as only one layer so shuld remove retun_sequences\n",
    "            if layer_number  == 1:\n",
    "                model.add(Bidirectional(LSTM(n_units[i]),\n",
    "                                        input_shape=(max_Bayt_length, char_dimension)))\n",
    "            # if NN has many layers so should add return_sequences\n",
    "            else:\n",
    "                model.add(Bidirectional(LSTM(n_units[i], return_sequences=True),\n",
    "                                        input_shape=(max_Bayt_length, char_dimension)))\n",
    "        # if it's not the first layer\n",
    "        else:\n",
    "            #check if last layer\n",
    "            if layer_number-1 == n:\n",
    "                model.add(Bidirectional(LSTM(n_units[i])))\n",
    "            else:\n",
    "                model.add(Bidirectional(LSTM(n_units[i], return_sequences=True)))\n",
    "    #check if there Dopout or not\n",
    "    if drop_out_rate != 0:\n",
    "        model.add(Dropout(drop_out_rate,seed=seed))\n",
    "\n",
    "                      \n",
    "#add softmax layer\n",
    "model.add(Dense(units = numbber_of_bohor,activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading last weights in last epoch\n",
      "last check point\n",
      "../Experiement/checkpoints/Experiment_test/weights-improvement-last-epoch.hdf5\n"
     ]
    }
   ],
   "source": [
    "#==================================check to load last epoch====================\n",
    "# load weights\n",
    "if(load_weights_flag == 1):\n",
    "    try:\n",
    "        print(\"loading last weights in last epoch\")\n",
    "        #List all avialble checkpoints into the directory\n",
    "        checkpoints_path_list = os.listdir(checkpoints_path)\n",
    "        all_checkpoints_list = [os.path.join(checkpoints_path,i) for i in checkpoints_path_list]\n",
    "        #Get the last inserted weight into the checkpoint_path\n",
    "        all_checkpoints_list_sorted = sorted(all_checkpoints_list, key=os.path.getmtime)\n",
    "        if(last_or_max_val_acc == 0):\n",
    "            print (\"last check point\")\n",
    "            if \"last\" in all_checkpoints_list_sorted[-1]:\n",
    "                print(all_checkpoints_list_sorted[-1])\n",
    "                max_weight_checkpoints =  all_checkpoints_list_sorted[-1]\n",
    "                #load weights\n",
    "#                 model = keras.models.load_model(max_weight_checkpoints)\n",
    "            else:\n",
    "                sys.exit(0)\n",
    "        else:\n",
    "            print (\"max_weight_checkpoints\")\n",
    "            print(all_checkpoints_list_sorted[-2])\n",
    "            max_weight_checkpoints =  all_checkpoints_list_sorted[-2]\n",
    "#             #load weights\n",
    "#             model = keras.models.load_model(max_weight_checkpoints)\n",
    "\n",
    "    except IOError:\n",
    "        print('An error occured trying to read the file.')\n",
    "    except:\n",
    "        if \"last\" not in  all_checkpoints_list_sorted[-1]:\n",
    "            sys.exit(\"Last epoch don't exist in this modle , you can make last_or_max_val_acc=1 to load the epoch has max val_acc\")\n",
    "        else:\n",
    "            print(\"No wieghts avialable \\n check the paths\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#==================================compile model===============================        \n",
    "# Compiling the RNN\n",
    "model.compile(optimizer = 'adam', \n",
    "              loss='categorical_crossentropy',\n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add  checkpoint - tensorboard\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_1 (GRU)                  (None, 93, 200)           123600    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 93, 200)           0         \n",
      "_________________________________________________________________\n",
      "gru_2 (GRU)                  (None, 93, 200)           240600    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 93, 200)           0         \n",
      "_________________________________________________________________\n",
      "gru_3 (GRU)                  (None, 200)               240600    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 6)                 1206      \n",
      "=================================================================\n",
      "Total params: 606,006\n",
      "Trainable params: 606,006\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "class last_epoch_saver(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        #save last epoch weghits \n",
    "        self.model.save(checkpoints_path+\"weights-improvement-last-epoch.hdf5\")\n",
    "        print(\"Save last epoch Done! ....\")\n",
    "\n",
    "\n",
    "#==============================Callbacks========================================\n",
    "checkpoint = ModelCheckpoint(check_points_file_path, \n",
    "                             monitor='val_acc', \n",
    "                             verbose=1,\n",
    "                             save_best_only=True, \n",
    "                             mode='max')\n",
    "\n",
    "tensorboard  = keras.callbacks.TensorBoard(log_dir=board_log_dir , \n",
    "                                           histogram_freq=0, \n",
    "                                           batch_size=50, \n",
    "                                           write_graph=True, \n",
    "                                           write_grads=True, \n",
    "                                           write_images=True, \n",
    "                                           embeddings_freq=0, \n",
    "                                           embeddings_layer_names=None, \n",
    "                                           embeddings_metadata=None)\n",
    "\n",
    "earlystopping = keras.callbacks.EarlyStopping(monitor='val_acc',\n",
    "                                             min_delta=0,\n",
    "                                             patience=earlystopping_patience,\n",
    "                                             verbose=1,\n",
    "                                             mode='auto')\n",
    "last_epoch_saver_ = last_epoch_saver()\n",
    "\n",
    "\n",
    "if earlystopping_patience ==-1:\n",
    "    callbacks_list = [checkpoint,tensorboard,last_epoch_saver_]\n",
    "    print(\"Add  checkpoint - tensorboard - last_epoch_saver_\")\n",
    "else:\n",
    "    callbacks_list = [checkpoint,tensorboard,earlystopping,last_epoch_saver_]\n",
    "    print(\"Add  checkpoint - tensorboard - earlystopping - last_epoch_saver_\")\n",
    "\n",
    "    \n",
    "\n",
    "callbacks_list = [checkpoint,my]\n",
    "    \n",
    "print(model.summary())\n",
    "#==============================================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 81 samples, validate on 9 samples\n",
      "Epoch 1/5\n",
      "64/81 [======================>.......] - ETA: 1s - loss: 1.4156e-07 - acc: 1.0000Epoch 00000: val_acc improved from -inf to 1.00000, saving model to ../Experiement/checkpoints/Experiment_test//weights-improvement-00-1.00.hdf5\n",
      "Save last epoch Done! ....\n",
      "81/81 [==============================] - 7s - loss: 1.4349e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 2/5\n",
      "64/81 [======================>.......] - ETA: 0s - loss: 1.2945e-07 - acc: 1.0000Epoch 00001: val_acc did not improve\n",
      "Save last epoch Done! ....\n",
      "81/81 [==============================] - 4s - loss: 1.2951e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 3/5\n",
      "64/81 [======================>.......] - ETA: 0s - loss: 1.3504e-07 - acc: 1.0000Epoch 00002: val_acc did not improve\n",
      "Save last epoch Done! ....\n",
      "81/81 [==============================] - 4s - loss: 1.3245e-07 - acc: 1.0000 - val_loss: 1.2583e-07 - val_acc: 1.0000\n",
      "Epoch 4/5\n",
      "64/81 [======================>.......] - ETA: 0s - loss: 1.2107e-07 - acc: 1.0000Epoch 00003: val_acc did not improve\n",
      "Save last epoch Done! ....\n",
      "81/81 [==============================] - 3s - loss: 1.2362e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 5/5\n",
      "64/81 [======================>.......] - ETA: 0s - loss: 1.2107e-07 - acc: 1.0000Epoch 00004: val_acc did not improve\n",
      "Save last epoch Done! ....\n",
      "81/81 [==============================] - 4s - loss: 1.2068e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "#=============================Fitting Model====================================\n",
    "# Fitting the RNN to the Training set\n",
    "hist = model.fit(X_train, \n",
    "                 Y_train, \n",
    "                 validation_split = validation_split_param, \n",
    "                 epochs=epochs_param, \n",
    "                 batch_size=batch_size_param, \n",
    "                 callbacks=callbacks_list,\n",
    "                 verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#save last epoch weghits \n",
    "model.save(checkpoints_path+\"weights-improvement-last-epoch.hdf5\")\n",
    "print(\"Save last epoch Done! ....\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "711/711 [==============================] - 13s    \n",
      "Accuracy: 64.14%\n"
     ]
    }
   ],
   "source": [
    "#===========================Evaluate model=====================================\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, Y_test, verbose=1)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../Experiement/checkpoints/Experiment_test//weights-improvement-{epoch:02d}-{val_acc:.2f}.hdf5'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean English Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import string\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('../data/english_dataset.csv', encoding = \"utf-8\",index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7105"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset.columns = ['Verse','Meter']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Verse', 'Meter'], dtype='object')"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset['Verse'] = dataset['Verse'].map(lambda x: x.lower())\n",
    "dataset['Meter'] = dataset['Meter'].map(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Verse</th>\n",
       "      <th>Meter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>humpty dumpty sat on a wall</td>\n",
       "      <td>dactyl</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Verse    Meter\n",
       "0  humpty dumpty sat on a wall   dactyl"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "english_alphapets=list(string.ascii_lowercase)+[\" \",\"\\'\"]\n",
    "our_alphabets = \"\".join(english_alphapets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset['Verse']=dataset['Verse'].apply(lambda x: re.sub(r'[^'+our_alphabets+']','',str(x))).apply(\n",
    "                                          lambda x: re.sub(r'  *',\" \",x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alphabets = set() \n",
    "def f(x): \n",
    "    global alphabets\n",
    "    alphabets|=set(x)\n",
    "total = math.ceil(len(dataset)/100)\n",
    "for i in range(total):\n",
    "    s=i*100\n",
    "    e=(i*100)+100\n",
    "    if e>len(dataset):\n",
    "        e=len(dataset)\n",
    "    new = dataset[s:e]['Verse'].map(f)\n",
    "\n",
    "len(alphabets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{' ',\n",
       " \"'\",\n",
       " 'a',\n",
       " 'b',\n",
       " 'c',\n",
       " 'd',\n",
       " 'e',\n",
       " 'f',\n",
       " 'g',\n",
       " 'h',\n",
       " 'i',\n",
       " 'j',\n",
       " 'k',\n",
       " 'l',\n",
       " 'm',\n",
       " 'n',\n",
       " 'o',\n",
       " 'p',\n",
       " 'q',\n",
       " 'r',\n",
       " 's',\n",
       " 't',\n",
       " 'u',\n",
       " 'v',\n",
       " 'w',\n",
       " 'x',\n",
       " 'y',\n",
       " 'z'}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alphabets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset['Meter']=dataset['Meter'].apply(lambda x: re.sub(r'[^'+our_alphabets+']','',str(x))).apply(\n",
    "                                          lambda x: re.sub(r'  *',\" \",x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alphabets = set() \n",
    "def f(x): \n",
    "    global alphabets\n",
    "    alphabets|=set(x)\n",
    "total = math.ceil(len(dataset)/100)\n",
    "for i in range(total):\n",
    "    s=i*100\n",
    "    e=(i*100)+100\n",
    "    if e>len(dataset):\n",
    "        e=len(dataset)\n",
    "    new = dataset[s:e]['Meter'].map(f)\n",
    "\n",
    "len(alphabets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "93"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['Verse'].map(len).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset['Verse']=dataset['Verse'].apply(lambda x: x.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "93"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['Verse'].map(len).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['dactyl', 'pyrrhic', 'spondee', 'trochee', 'iambic', 'anapaest'], dtype=object)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['Meter'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset.to_csv('../data/english_dataset.csv', encoding = \"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset=pd.read_csv('../data/english_dataset.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Verse</th>\n",
       "      <th>Meter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>humpty dumpty sat on a wall</td>\n",
       "      <td>dactyl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>humpty dumpty had a great fall</td>\n",
       "      <td>dactyl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>humptys mother was very sad</td>\n",
       "      <td>dactyl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>to see her son in the hospital</td>\n",
       "      <td>dactyl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>humpty dumpty was slowly dying</td>\n",
       "      <td>dactyl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>humpty dumpty was painfully frying</td>\n",
       "      <td>dactyl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>he said that there was only one cure</td>\n",
       "      <td>dactyl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>just give me one popsicle</td>\n",
       "      <td>dactyl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>adam and eve</td>\n",
       "      <td>dactyl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>john milton</td>\n",
       "      <td>dactyl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>dont eat that fruit</td>\n",
       "      <td>dactyl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>thought they could</td>\n",
       "      <td>dactyl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>tree of knowledge</td>\n",
       "      <td>dactyl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>insubordination</td>\n",
       "      <td>dactyl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>downfall occurs</td>\n",
       "      <td>dactyl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>evil be thou my good</td>\n",
       "      <td>dactyl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>depths of wisdom</td>\n",
       "      <td>dactyl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>hermann hesse</td>\n",
       "      <td>dactyl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>spiritualitys quest</td>\n",
       "      <td>dactyl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>souls transformation</td>\n",
       "      <td>dactyl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>enlightenment assured</td>\n",
       "      <td>dactyl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>corporealization</td>\n",
       "      <td>dactyl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>the oneness of all</td>\n",
       "      <td>dactyl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>siddharthas realization</td>\n",
       "      <td>dactyl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>im looking at your eyes it is close in</td>\n",
       "      <td>dactyl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>a dream i had touch your face in my</td>\n",
       "      <td>dactyl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>heart it is smooth like marble i want</td>\n",
       "      <td>dactyl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>to see you in sleeping i want to play</td>\n",
       "      <td>dactyl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>with your fingers to disturb you in</td>\n",
       "      <td>dactyl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>sleeping lets tell you a story once</td>\n",
       "      <td>dactyl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7075</th>\n",
       "      <td>homewardthenhesailedexulting</td>\n",
       "      <td>trochee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7076</th>\n",
       "      <td>homewardthroughtheblackpitch water</td>\n",
       "      <td>trochee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7077</th>\n",
       "      <td>homewardthroughthewelteringserpents</td>\n",
       "      <td>trochee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7078</th>\n",
       "      <td>withthetrophiesofthebattle</td>\n",
       "      <td>trochee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7079</th>\n",
       "      <td>withashoutandsongoftriumph</td>\n",
       "      <td>trochee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7080</th>\n",
       "      <td>ontheshorestoodoldnokomis</td>\n",
       "      <td>trochee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7081</th>\n",
       "      <td>ontheshorestoodchibiabos</td>\n",
       "      <td>trochee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7082</th>\n",
       "      <td>andtheverystrongmankwasind</td>\n",
       "      <td>trochee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7083</th>\n",
       "      <td>waitingforthehero'scoming</td>\n",
       "      <td>trochee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7084</th>\n",
       "      <td>listeningtohissongsoftriumph</td>\n",
       "      <td>trochee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7085</th>\n",
       "      <td>andthepeopleofthevillage</td>\n",
       "      <td>trochee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7086</th>\n",
       "      <td>welcomedhimwithsongsanddances</td>\n",
       "      <td>trochee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7087</th>\n",
       "      <td>madeajoyousfeastandshouted</td>\n",
       "      <td>trochee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7088</th>\n",
       "      <td>honorbetohiawatha</td>\n",
       "      <td>trochee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7089</th>\n",
       "      <td>hehasslainthegreatpearl feather</td>\n",
       "      <td>trochee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7090</th>\n",
       "      <td>slainthemightiestofmagicians</td>\n",
       "      <td>trochee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7091</th>\n",
       "      <td>himwhosentthefieryfever</td>\n",
       "      <td>trochee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7092</th>\n",
       "      <td>sentthewhitefogfromthefen lands</td>\n",
       "      <td>trochee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7093</th>\n",
       "      <td>sentdiseaseanddeathamongus</td>\n",
       "      <td>trochee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7094</th>\n",
       "      <td>everdeartohiawatha</td>\n",
       "      <td>trochee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7095</th>\n",
       "      <td>wasthememoryofmama</td>\n",
       "      <td>trochee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7096</th>\n",
       "      <td>andintokenofhisfriendship</td>\n",
       "      <td>trochee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7097</th>\n",
       "      <td>asamarkofhisremembrance</td>\n",
       "      <td>trochee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7098</th>\n",
       "      <td>headornedanddeckedhispipe stem</td>\n",
       "      <td>trochee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7099</th>\n",
       "      <td>withthecrimsontuftoffeathers</td>\n",
       "      <td>trochee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7100</th>\n",
       "      <td>withtheblood redcrestofmama</td>\n",
       "      <td>trochee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7101</th>\n",
       "      <td>butthewealthofmegissogwon</td>\n",
       "      <td>trochee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7102</th>\n",
       "      <td>allthetrophiesofthebattle</td>\n",
       "      <td>trochee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7103</th>\n",
       "      <td>hedividedwithhispeople</td>\n",
       "      <td>trochee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7104</th>\n",
       "      <td>shareditequallyamongthem</td>\n",
       "      <td>trochee</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7105 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Verse    Meter\n",
       "0                humpty dumpty sat on a wall   dactyl\n",
       "1             humpty dumpty had a great fall   dactyl\n",
       "2                humptys mother was very sad   dactyl\n",
       "3             to see her son in the hospital   dactyl\n",
       "4             humpty dumpty was slowly dying   dactyl\n",
       "5         humpty dumpty was painfully frying   dactyl\n",
       "6       he said that there was only one cure   dactyl\n",
       "7                  just give me one popsicle   dactyl\n",
       "8                               adam and eve   dactyl\n",
       "9                                john milton   dactyl\n",
       "10                       dont eat that fruit   dactyl\n",
       "11                        thought they could   dactyl\n",
       "12                         tree of knowledge   dactyl\n",
       "13                           insubordination   dactyl\n",
       "14                           downfall occurs   dactyl\n",
       "15                      evil be thou my good   dactyl\n",
       "16                          depths of wisdom   dactyl\n",
       "17                             hermann hesse   dactyl\n",
       "18                       spiritualitys quest   dactyl\n",
       "19                      souls transformation   dactyl\n",
       "20                     enlightenment assured   dactyl\n",
       "21                          corporealization   dactyl\n",
       "22                        the oneness of all   dactyl\n",
       "23                   siddharthas realization   dactyl\n",
       "24    im looking at your eyes it is close in   dactyl\n",
       "25       a dream i had touch your face in my   dactyl\n",
       "26     heart it is smooth like marble i want   dactyl\n",
       "27     to see you in sleeping i want to play   dactyl\n",
       "28       with your fingers to disturb you in   dactyl\n",
       "29       sleeping lets tell you a story once   dactyl\n",
       "...                                      ...      ...\n",
       "7075            homewardthenhesailedexulting  trochee\n",
       "7076      homewardthroughtheblackpitch water  trochee\n",
       "7077     homewardthroughthewelteringserpents  trochee\n",
       "7078              withthetrophiesofthebattle  trochee\n",
       "7079              withashoutandsongoftriumph  trochee\n",
       "7080               ontheshorestoodoldnokomis  trochee\n",
       "7081                ontheshorestoodchibiabos  trochee\n",
       "7082              andtheverystrongmankwasind  trochee\n",
       "7083               waitingforthehero'scoming  trochee\n",
       "7084            listeningtohissongsoftriumph  trochee\n",
       "7085                andthepeopleofthevillage  trochee\n",
       "7086           welcomedhimwithsongsanddances  trochee\n",
       "7087              madeajoyousfeastandshouted  trochee\n",
       "7088                       honorbetohiawatha  trochee\n",
       "7089         hehasslainthegreatpearl feather  trochee\n",
       "7090            slainthemightiestofmagicians  trochee\n",
       "7091                 himwhosentthefieryfever  trochee\n",
       "7092         sentthewhitefogfromthefen lands  trochee\n",
       "7093              sentdiseaseanddeathamongus  trochee\n",
       "7094                      everdeartohiawatha  trochee\n",
       "7095                      wasthememoryofmama  trochee\n",
       "7096               andintokenofhisfriendship  trochee\n",
       "7097                 asamarkofhisremembrance  trochee\n",
       "7098          headornedanddeckedhispipe stem  trochee\n",
       "7099            withthecrimsontuftoffeathers  trochee\n",
       "7100             withtheblood redcrestofmama  trochee\n",
       "7101               butthewealthofmegissogwon  trochee\n",
       "7102               allthetrophiesofthebattle  trochee\n",
       "7103                  hedividedwithhispeople  trochee\n",
       "7104                shareditequallyamongthem  trochee\n",
       "\n",
       "[7105 rows x 2 columns]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "iambic      2155\n",
       "dactyl      1993\n",
       "anapaest    1022\n",
       "trochee     1000\n",
       "pyrrhic      740\n",
       "spondee      195\n",
       "Name: Meter, dtype: int64"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['Meter'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# make one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import string\n",
    "import pandas as pd\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('../data/english_dataset.csv', encoding = \"utf-8\",index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Verse</th>\n",
       "      <th>Meter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>humpty dumpty sat on a wall</td>\n",
       "      <td>dactyl</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Verse   Meter\n",
       "0  humpty dumpty sat on a wall  dactyl"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "93"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxlen= dataset['Verse'].map(len).max()\n",
    "maxlen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alphabet1=list(string.ascii_lowercase)+[' ', '\\''] #Add space and apostrophe to our alphabets\n",
    "alphabet = dict((c, i) for i, c in enumerate(alphabet1))\n",
    "alphabet_ = dict((i, c) for i, c in enumerate(alphabet1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def one(num):\n",
    "    a = np.zeros(len(alphabet1))\n",
    "    a[num] = 1\n",
    "    return a\n",
    "\n",
    "def one_hot(verse):\n",
    "    d = maxlen - len(verse)\n",
    "    verse = verse + \" \"*d\n",
    "    data = [one(alphabet[char]) for char in verse]\n",
    "#     return np.asarray(tf.Session().run(tf.one_hot(indices=data,depth=len(alphabet1))).tolist())\n",
    "    return np.asarray(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res = dataset['Verse'].map(one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result= np.stack(res,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7105, 93, 28)"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Verse</th>\n",
       "      <th>Meter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>humpty dumpty sat on a wall</td>\n",
       "      <td>dactyl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>humpty dumpty had a great fall</td>\n",
       "      <td>dactyl</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Verse   Meter\n",
       "0     humpty dumpty sat on a wall  dactyl\n",
       "1  humpty dumpty had a great fall  dactyl"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def from_one_hot_to_char(arr): \n",
    "    a = []\n",
    "    for ii in arr:\n",
    "        a.append([alphabet_[i] for i,l in enumerate(ii) if int(l)==1][0])\n",
    "    return \"\".join(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "def save(nameOfFile,nameOfDataset,dataVar):\n",
    "    h5f = h5py.File(nameOfFile, 'w')\n",
    "    h5f.create_dataset(nameOfDataset, data=dataVar)\n",
    "    h5f.close()\n",
    "#---------------------------Retrive Encoding--------------------------------------\n",
    "def restore (nameOfFile,nameOfDataset):\n",
    "    h5f = h5py.File(nameOfFile,'r')\n",
    "    matrix = h5f[nameOfDataset][:]\n",
    "    h5f.close()\n",
    "    return matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save(\"../data/data_matrix_X_one_hot_encoding.h5\",\"X\",result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
