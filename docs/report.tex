\documentclass[12pt]{article}
\usepackage{multicol}


%% Drawing
\usepackage{tikz}
\usetikzlibrary{arrows} % For arrows :"D

% For Arabic
\usepackage{polyglossia}
\setmainlanguage{english}
\setotherlanguage{arabic}
\newfontfamily\arabicfont[Script=Arabic]{Amiri}



\begin{document}


\begin{titlepage}

\newcommand{\HRule}{\rule{\linewidth}{0.5mm}} % Defines a new command for the horizontal lines, change thickness here

\center % Center everything on the page
 
%-----------------------
%	HEADING SECTIONS
%-----------------------

\textsc{\LARGE Helwan University}\\[1.5cm] % Name of your university/college
\textsc{\Large \textarabic{لا غالب إلا الله}}\\[0.5cm] % Major heading such as course name

%-----------------------
%	TITLE SECTION
%-----------------------

\HRule \\[0.4cm]
{ \LARGE \bfseries Learning meters of Arabic and English poems}\\[0.4cm] % Title of your document
\HRule \\[1.5cm]
 
%-----------------------
%	AUTHOR SECTION
%-----------------------

\begin{minipage}{0.4\textwidth}
\begin{flushleft} \large
\emph{Members, \textit{\small alphabetically ordered}:}\\

\small{Abdaullah Ramzy}\\
\small{Ali Abdemoniem}\\
\small{Ali Osama}\\
\small{Taha Magdy}\\
\small{Umar Mohamed}\\
\end{flushleft}
\end{minipage}
~
\begin{minipage}{0.4\textwidth}
\begin{flushright} \large
\emph{Supervisor:} \\
Prof. Waleed A.\textsc{Yousuf} % Supervisor's Name
\end{flushright}
\end{minipage}\\[2cm]

% If you don't want a supervisor, uncomment the two lines below and remove the section above
%\Large \emph{Author:}\\
%John \textsc{Smith}\\[3cm] % Your name

%-----------------------
%	DATE SECTION
%-----------------------

{\large \today}\\[2cm] % Date, change the \today to a set date if you want to be precise

%-----------------------
%	LOGO SECTION
%-----------------------
\includegraphics[width=30mm,scale=0.5]{logo.png}\\[1cm] % Include a department/university logo - this will require the graphicx package

\vfill % Fill the rest of the page with whitespace

\end{titlepage}
%\tableofcontents \newpage




%%%%%%
\section{Introduction and Problem Statement}
Detecting the meter of poems is not an easy task for ordinary people, but how
computers will perform? Our task is to train a model so that it can detect the
meter of the input verse/text.
We have worked on Arabic and English in parallel, everything thing is applied to
Arabic is applied also in English, as possible as we can.

To be clearer, the model's input is a verse/text \textarabic{بيت شعر} and the
output is a class which is the verse's meter \textarabic{البحر}, as shown in the
figure below.


% FIGURE
\begin{center}
\begin{tikzpicture}
\centering

%\draw[step=0.5, gray, very thin] (0,0) grid (6,2);
\draw[rounded corners=2pt, thick] (2,0) rectangle (2+2,2);
\node at (3, 1.5) {Deep};
\node at (3, 1) {Learning};
\node at (3, 0.5) {Model};

\draw[arrows=-angle 90, line width=1pt ] (1, 1) -- (1 +1 -0.1, 1);
\node at (0, 1.5) {Verse};
\node at (0, 1) {\textarabic{بيتُ الشعر}};

\draw[arrows=-angle 90, line width=1pt] (4 +.1, 1) -- (4 +1, 1);
\node at (6, 1.5) {Meter};
\node at (6, 1) {\textarabic{البحْرُ}};

\end{tikzpicture}
\end{center}

The output variable is a class/categorical, then our problem can be described as
\textit{supervised learning  classification}.  We have trained some deep learning
models such as LSTM, Bi-LSTM and GRU.  Those models are chosen because of the
nature of our problem. We were trying to detect the verse's meter, which is a
sequence of characters and \textit{recurrent neural network} are suitable  to
learn that pattern, thanks to its cell's share-memory and its recursive
structure.


\section{The Project Road Map}
This is are four-stage project.  The first one is where we get the raw data and
put it is a feature-response form, the second stage is cleaning the data, by that
we mean that any non-letter character and unnecessary white-spaces are removed,
also, handling any diacritics issue, as it will be demonstrated in the next
sections, this stage include encoding the data to the form that is suitable to be
fed to our neural networks. 

The third stage is where the models are built and are tuned then we have
automated the experiments to run all the iterations one after another, much
details will be presented. Finally, we gather the results and analyse them, also
we then conduct some additional experiments to see the language and encoding
effect over the learning curve.  The first two steps were much difficult than
building the models. The following figure shows the road map.

\begin{center}
\begin{tikzpicture}
\centering

%\draw[step=0.5, gray, very thin] (-6,0) grid (6.5,2);

\draw[rounded corners=2pt, thick] (-6, 0) rectangle (-6 +2,2);
\draw[rounded corners=2pt, thick] (-2.5, 0) rectangle (-2.5 +2,2);
\draw[rounded corners=2pt, line width=2pt] (1, 0) rectangle (1 +2,2);
\draw[rounded corners=2pt, thick] (4.5, 0) rectangle (4.5 +2,2);


\node at (2, 1.2) {Building};
\node at (2, .7) {Models};

\node at (-1.5, 1.2) {Cleaning};
\node at (-1.5, .7) {Data};

\node at (-5, 1.5) {Scraping};
\node at (-5, 1) {The};
\node at (-5, .5) {Web};
\node at (-5, -.5) {\small \textit{Gathering Data}};

\node at (5.5, 1.2) {Analysing};
\node at (5.5, .7) {Results};

\def \littelM {0.1}
\draw[arrows=-angle 90, line width=1pt] (-6 +2 +\littelM, 1) -- (-2.5 -\littelM, 1);
\draw[arrows=-angle 90, line width=1pt] (-2.5 +2 +\littelM, 1) -- (1 -\littelM, 1);
\draw[arrows=-angle 90, line width=1pt] ( 1 +2 +\littelM, 1) -- (4.5 -\littelM, 1);

\end{tikzpicture}
\end{center}




\section{Scraping The Web \textit{\small --gathering the data}}

\subsection{Data Set}
\subsubsection{Arabic dataset}
We have scrapped the Arabic dataset from two big poetry websites:
\textarabic{الديوان}\footnote{\textit{aldiwan.net}}, \textarabic{الموسوعة
الشعرية}\footnote{\textit{poetry.tcaabudhabi.ae}}. Both are merged into one large
dataset.  The total number of verses is  1,862,046 poetic verses; each verse is
labeled by its meter, the poet who wrote it, and the
age which it was written in. There are 22 meters, 3701 poets and 11
ages; and they are Pre-Islamic, Islamic, Umayyad, Mamluk, Abbasid, Ayyubid, Ottoman,
Andalusian, era between Umayyad and Abbasid, Fatimid and modern.  We are only
interested  in the 16 classic meters which are attributed to \textit{Al-Farahidi},
and they are the majority of the dataset with a total number of 1,722,321
verses\footnote{https://wwww.github.com/tahamagdy}.


% NOTE: convert it to a line chart
% NOTE: add annotations; percentages of each class from the data size. 
\begin{table}[!t]
  \centering
  \begin{tabular}{|c|c|} 
    \hline
    \textbf{Meter} & \textbf{Verses Count} \\ 
    \hline
    Al-Taweel       &     416,428 \\
    Al-Kamel        &     370,116 \\
    Al-Baseet       &     244,583 \\
    Al-Khafeef      &     157,880 \\
    Al-Wafeer       &     143,148 \\
    Al-Rigz         &     119,286 \\
    Al-Raml         &     79,560 \\
    Al-Motakarib    &     63,613 \\
    Al-Sar'e        &     59,370 \\
    Al-Monsafeh     &     28,768 \\
    Al-Mogtath      &     18,062 \\
    Al-Madeed       &     7,808 \\
    Al-Hazg         &     7,468 \\
    Al-Motadarik    &     5,144 \\
    Al-Moktadib     &     799 \\
    Al-Modar'e      &     288 \\
    \hline
  \end{tabular}
  \caption{\textit{The size of each class}}
  \label{data_size}
\end{table}
% NOTE: add a line-chart like arabic + percentatge for every class.
\subsubsection{English dataset}
The English dataset is scraped from many different web
resources\footnote{http://www.eighteenthcenturypoetry.org}. It consists of 199,002
verses, each of them is labeled with one of these four meters: \textit{Iambic},
\textit{Trochee}, \textit{Dactyl} and \textit{Anapaestic}.  The \textit{Iambic}
class dominates the dataset; there are  186,809 \textit{Iambic} verses, 5418
\textit{Trochee} verses, 5378  \textit{Anapaestic} verses, 1397 \textit{Dactyl}
verses.  We have downsampled the \textit{Iambic} class to 5550 verses.



\section{Cleaning Data}

\section{Building the models}
\subsection{Data Encoding}
\subsection{Models}


\section{Analysing Results}

\section{Tools}
Python is pseudo-code like programming language, it is so easy and high-level
that we can describe complex structures in a few lines of code, the main second
reason is that python recently has been so papular in the Artificial Intelligence
community. Its library is so rich with packages for Machine Learning, Deep
Learning, data manipulation, even for web-scraping; we don't need to parse HTML
by you hands.

We have used:
Two columns:
    \begin{multicols}{2}
\begin{itemize}
\item \textit{Python} 3.6.5
\item \textit{Keras} x.x for deep learning.
\item \textit{Tensorflow} x.x as back-end of Keras.
\item \textit{BeautifulSoup} for web scraping.
\end{itemize}
    \end{multicols}





\section{Gathering data}

% Figure of Project flow

\end{document}


