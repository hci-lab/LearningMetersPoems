{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import arabic\n",
    "import pyarabic\n",
    "import helpers\n",
    "from helpers import Clean_data,separate_token_with_dicrites,save_h5\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from numpy import array, argmax\n",
    "import os,errno,re,sys\n",
    "import pickle\n",
    "from itertools import product \n",
    "from pyarabic.araby import strip_tashkeel, strip_tatweel\n",
    "import h5py\n",
    "import random as rn\n",
    "##########################\n",
    "rn.seed(123456)\n",
    "np.random.seed(123456)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paths created\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    * Paths\n",
    "'''\n",
    "all_data_path = \"../../data/Almoso3a_Alshe3rya/data/All_ksaied.csv\"\n",
    "all_data_cleaned_path = \"../../data/Almoso3a_Alshe3rya/data/All_ksaied_cleaned.csv\"\n",
    "\n",
    "'''\n",
    "    * Creating Directories which will contain the Encoded data.\n",
    "'''\n",
    "try:\n",
    "    os.makedirs(\"../../data/Encoded/8bits/WithoutTashkeel/Eliminated/\")\n",
    "    os.makedirs(\"../../data/Encoded/8bits/WithoutTashkeel/Full_Data/\")\n",
    "    os.makedirs(\"../../data/Encoded/8bits/WithTashkeel/Eliminated/\")\n",
    "    os.makedirs(\"../../data/Encoded/8bits/WithTashkeel/Full_Data/\")\n",
    "except OSError as e:\n",
    "    if e.errno != errno.EEXIST:\n",
    "        print(\"Can't create file for checkpoints or for logs please check \")\n",
    "        raise\n",
    "print(\"Paths created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/lib/arraysetops.py:472: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1831770\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    * Load and Clear\n",
    "'''\n",
    "all_data = pd.read_csv(all_data_path, index_col=0)\n",
    "print( len(all_data) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1831770 entries, 0 to 1835252\n",
      "Data columns (total 8 columns):\n",
      "العصر           object\n",
      "الشاعر          object\n",
      "الديوان         object\n",
      "القافية         object\n",
      "البحر           object\n",
      "الشطر الايسر    object\n",
      "الشطر الايمن    object\n",
      "البيت           object\n",
      "dtypes: object(8)\n",
      "memory usage: 1.8 GB\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    * (X,Y) form of the dataset. [uncleaned]\n",
    "'''\n",
    "all_data.info(memory_usage='deep')\n",
    "bahr = 'Bahr'\n",
    "bayt = 'Bayt_Text'\n",
    "#all_data  = all_data[[bayt, bahr]]\n",
    "bahr = 'البحر'\n",
    "bayt = 'البيت'\n",
    "all_data  = all_data[[bayt, bahr]]\n",
    "all_data.columns = ['Bayt_Text','Bahr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    * Cleaning Data\n",
    "    # Outputs:\n",
    "        $ all_data_cleaned\n",
    "        % Cleaned, and Ready for filtering, encoding\n",
    "'''\n",
    "\n",
    "# Computing the maximum bayt length\n",
    "MAX_LEN_BAYT = np.max((all_data.Bayt_Text.apply(pyarabic.araby.strip_tashkeel).apply(len)))\n",
    "\n",
    "\n",
    "# Cleaning \n",
    "all_data_cleaned = Clean_data(data_frame=all_data,\n",
    "                              max_bayt_len=MAX_LEN_BAYT,\n",
    "                              verse_column_name='Bayt_Text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean tatwieel and tanween + shadda\n",
    "all_data_cleaned['Bayt_Text'] = all_data_cleaned['Bayt_Text'].apply(pyarabic.araby.strip_tatweel)\n",
    "all_data_cleaned['Bayt_Text'] = all_data_cleaned['Bayt_Text'].apply(helpers.factor_shadda_tanwin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save cleaned data.\n",
    "all_data_cleaned.to_csv(all_data_cleaned_path, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Cleaned data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Unnamed: 0  Unnamed: 0.1  \\\n",
      "0                 0             0   \n",
      "1                 1             1   \n",
      "2                 2             2   \n",
      "3                 3             3   \n",
      "4                 4             4   \n",
      "5                 5             5   \n",
      "6                 6             6   \n",
      "7                 7             7   \n",
      "8                 8             8   \n",
      "9                 9             9   \n",
      "10               10            10   \n",
      "11               11            11   \n",
      "12               12            12   \n",
      "13               13            13   \n",
      "14               14            14   \n",
      "15               15            15   \n",
      "16               16            16   \n",
      "17               17            17   \n",
      "18               18            18   \n",
      "19               19            19   \n",
      "20               20            20   \n",
      "21               21            21   \n",
      "22               22            22   \n",
      "23               23            23   \n",
      "24               24            24   \n",
      "25               25            25   \n",
      "26               26            26   \n",
      "27               27            27   \n",
      "28               28            28   \n",
      "29               29            29   \n",
      "...             ...           ...   \n",
      "1831697     1831740       1835223   \n",
      "1831698     1831741       1835224   \n",
      "1831699     1831742       1835225   \n",
      "1831700     1831743       1835226   \n",
      "1831701     1831744       1835227   \n",
      "1831702     1831745       1835228   \n",
      "1831703     1831746       1835229   \n",
      "1831704     1831747       1835230   \n",
      "1831705     1831748       1835231   \n",
      "1831706     1831749       1835232   \n",
      "1831707     1831750       1835233   \n",
      "1831708     1831751       1835234   \n",
      "1831709     1831752       1835235   \n",
      "1831710     1831753       1835236   \n",
      "1831711     1831754       1835237   \n",
      "1831712     1831755       1835238   \n",
      "1831713     1831756       1835239   \n",
      "1831714     1831757       1835240   \n",
      "1831715     1831758       1835241   \n",
      "1831716     1831759       1835242   \n",
      "1831717     1831760       1835243   \n",
      "1831718     1831761       1835244   \n",
      "1831719     1831762       1835245   \n",
      "1831720     1831763       1835246   \n",
      "1831721     1831764       1835247   \n",
      "1831722     1831765       1835248   \n",
      "1831723     1831766       1835249   \n",
      "1831724     1831767       1835250   \n",
      "1831725     1831768       1835251   \n",
      "1831726     1831769       1835252   \n",
      "\n",
      "                                                 Bayt_Text    Bahr  \n",
      "0        خَليلَيْيَ لا تَستَعجِلا أَن تَزَوْوَدا وَأَن ...  الطويل  \n",
      "1        فَما لَبَثُنْ يَومنْ بِسابِقِنْ مَغنَمِنْ وَلا...  الطويل  \n",
      "2        وَإِن تُنظِراني اليَومَ أَقضِ لُبانَتَنْ وَتَس...  الطويل  \n",
      "3        لَعَمرُكَ ما نَفسُنْ بِجِدِنْ رَشيدَةتِنْ تُؤا...  الطويل  \n",
      "4        وَإِن ظَهَرَت مِنهُ قَوارِصُ جَمْمَتُنْ وَأَفر...  الطويل  \n",
      "5        عَلى غَيرِ ذَنبِنْ أَن أَكونَ جَنَيتُهُ سِوى ق...  الطويل  \n",
      "6        لَعَمري لَنِعمَ المَرءُ تَدعو بِحَبلِهِ إِذا م...  الطويل  \n",
      "7        عَظيمُ رَمادِ القِدرِ لا مُتَعَبْبِسُنْ وَلا م...  الطويل  \n",
      "8        وَإِن صَرْرَحَت كَحلُنْ وَهَبْبَت عَرِيْيَتُنْ...  الطويل  \n",
      "9        صَبَرتُ عَلى وَطءِ المَوالي وَحَطمِهِم إِذا ضَ...  الطويل  \n",
      "10       وَلم يَحمِ فَرجَ الحَيْيِ إِلْلا مُحافِظُنْ كَ...  الطويل  \n",
      "11       أَرى جارَتي خَفْفَت وَخَفْفَ نَصيحُها وَحُبْبَ...  الطويل  \n",
      "12       فَبيني على نَجمِنْ شَخيسِنْ نُحوسُهُ وَأَشأَمُ...  الطويل  \n",
      "13       فَإِن تَشغَبي فَالشَغَبُ مِنْني سَجِيْيَتُنْ إ...  الطويل  \n",
      "14       أُقارِضُ أَقوامنْ فَأوفي قُروضَهُم وَعَفُنْ إِ...  الطويل  \n",
      "15       عَلى أَنْنَ قَومي أَشَقَذوني فَأَصبَحَت دِياري...  الطويل  \n",
      "16       تَنَفْفَذَ مِنهُم نافِذاتُنْ فَسُؤنَني وَأَضمَ...  الطويل  \n",
      "17       فَقُلتُ فِراقُ الدارِ أَجمَلُ بَينَنا وَقَد يَ...  الطويل  \n",
      "18       عَلى أَنْنَني قَد أَدْدَعي بِأَبيهِمِ إِذا عَم...  الطويل  \n",
      "19       وَأَنْني أَرى ديني يُوافِقُ دينَهُم إِذا نَسَك...  الطويل  \n",
      "20       وَمَنزِلَةتِنْ بِالحَجْجِ أُخرى عَرَفتُها لَها...  الطويل  \n",
      "21       بِوُدْدِكِ ما قَومي عَلى أَن تَرَكتِهِم سُلَيم...  الطويل  \n",
      "22       إِذا النَجمُ أَمسى مَغرِبَ الشَمسِ رائِبنْ وَل...  الطويل  \n",
      "23       وَغابَ شُعاعُ الشَمسِ في غَيرِ جُلبَةتِنْ وَلا...  الطويل  \n",
      "24       وَهاجَ عَماءُنْ مُقشَعِرُنْ كَأَنْنَهُ نَقيلَة...  الطويل  \n",
      "25       إِذا عُدِمَ المَحلوبُ عادَت عَلَيهِمُ قُدورُنْ...  الطويل  \n",
      "26       يَثوبُ إِلَيها كُلْلُ ضَيفِنْ وَجانِبِنْ كَما ...  الطويل  \n",
      "27       بِأَيديهِمُ مَقرومَتُنْ وَمَغالِقُنْ يَعودُ بِ...  الطويل  \n",
      "28       وَمَلمومَةتِنْ لا يَخرِقُ الطَرفُ عَرضَها لَها...  الطويل  \n",
      "29       تَسيرُ وَتُزجي السَمْمَ تَحتَ نُحورِها كَريهُن...  الطويل  \n",
      "...                                                    ...     ...  \n",
      "1831697  وأقول خير الناس بعد محمد صِدْديقه وأنيسه في الغار  الكامل  \n",
      "1831698   ثم الثلاثة بعده خير الورى أكرم بهم من سادة أطهار  الكامل  \n",
      "1831699  هذا اعتقادي والذي أرجو به فوزي وعتقي من عذاب ا...  الكامل  \n",
      "1831700  يا رب إني قد أتيتك تائبنْ من زلتي يا عالم الأسرار  الكامل  \n",
      "1831701  وعدلت عما كنت معتقدنْ له في الصحب صحب نبيك الم...  الكامل  \n",
      "1831702    السيد الصديق والعدل الرضى عمر وعثمان شهيد الدار  الكامل  \n",
      "1831703  بادر لميزاب ماءِنْ كاللجين بدا يهدي لنا دررنْ ...  البسيط  \n",
      "1831704  لقد حكى فيضه إذ جاء مندفقنْ فياض كف بشير المجد...  البسيط  \n",
      "1831705  ألا يا لقوم للخلال الخسائس ورفعة ارجاسِنْ برغم...  الطويل  \n",
      "1831706  قفوا فانظروا إذ ضمت الشمل ندوتَنْ لحادثة من في...  الطويل  \n",
      "1831707  تروا من شيوخ السوء فيها عصابتَنْ ابالس أضحوا ف...  الطويل  \n",
      "1831708  صعاليك أموال اليتامى ذئابها قراطبة البيداء حتف...  الطويل  \n",
      "1831709  وهم شهداء الزور من قلة التقى لحوز منالات إليهم...  الطويل  \n",
      "1831710  يعدون ما دون البتيكات وضحا رش لهم من ترهات الب...  الطويل  \n",
      "1831711  بها حللوا عين الحرام وحرموا ال حلال اتساعنْ في...  الطويل  \n",
      "1831712  كما غصبوا الأملاك معشوقة الورى وما سجلوا أيضنْ...  الطويل  \n",
      "1831713  فيا وحشتي منهم إذا اكتحلت بهم جفوني وأنسى بالو...  الطويل  \n",
      "1831714  مضى الرؤساء الأولون واصبحت عراص المعالي كالطلو...  الطويل  \n",
      "1831715     أوشك القلب أن يذوب ويفنى وأنا لم أزل بها أتغنى  الخفيف  \n",
      "1831716  هي عندي معنى الحياة وعندي هي معنى الردى ومعنى ...  الخفيف  \n",
      "1831717  هي أخت الهواء طلق هواها وهي أخت الضياء روحنْ و...  الخفيف  \n",
      "1831718  هي نهرُنْ من الرواء وصرحُنْ أبديُنْ من السناء ...  الخفيف  \n",
      "1831719      هي إشراقة تشعشع كالفجر تحيل الفناء بعثنْ وفنا  الخفيف  \n",
      "1831720   هي نفس تواجدت وهي روح تنشد الشعر وهي قلب مُعنْنى  الخفيف  \n",
      "1831721          هي لحن محلق عبقري وستبقي إلى القيامة لحنا  الخفيف  \n",
      "1831722  هي أغلى ما أنشأ اللْلَه في الدنيا وأحلى قصيدة ...  الخفيف  \n",
      "1831723   هي أغرودة الأغاريد تنساب كحلم يغشى الجفون الوسنى  الخفيف  \n",
      "1831724         هي شلال بهجة وبهاء يتداعى وجدنْ ويخفق حسنا  الخفيف  \n",
      "1831725  هي حلم الهوى ومنطلقي الباقي يدك الحدود سجننْ ف...  الخفيف  \n",
      "1831726     هي حبي العاتي وكل غرامي آه لو أدرك الغرام لجنا  الخفيف  \n",
      "\n",
      "[1831727 rows x 4 columns]\n",
      "111\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    * Load the cleaned Data\n",
    "'''\n",
    "all_data_cleaned = pd.read_csv(all_data_cleaned_path)\n",
    "all_data_cleaned = all_data_cleaned.dropna()\n",
    "print(all_data_cleaned)\n",
    "# Computing the maximum bayt length\n",
    "MAX_LEN_BAYT = np.max((all_data_cleaned.Bayt_Text.apply(pyarabic.araby.strip_tashkeel).apply(len)))\n",
    "print(MAX_LEN_BAYT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['الوافر', 'المنسرح', 'المجتث', 'المتقارب', 'الكامل', 'الطويل', 'السريع', 'الرمل', 'الرجز', 'الخفيف', 'البسيط']\n",
      "['الوافر', 'المنسرح', 'المديد', 'المجتث', 'المتقارب', 'الكامل', 'الطويل', 'السريع', 'الرمل', 'الرجز', 'الخفيف', 'البسيط', 'المقتضب', 'الهزج', 'المضارع', 'المتدارك']\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    * Filtering the data\n",
    "    # Outputs:\n",
    "        1 all_filtered_data\n",
    "        2 eliminated_filtered_data\n",
    "'''\n",
    "\n",
    "elminated_classic_bohor = ['الوافر', 'المنسرح','المجتث', 'المتقارب', 'الكامل', 'الطويل', 'السريع', 'الرمل',\n",
    "                         'الرجز', 'الخفيف', 'البسيط']\n",
    "\n",
    "full_bohor_classes = ['الوافر', 'المنسرح', 'المديد', 'المجتث', 'المتقارب', 'الكامل', 'الطويل', 'السريع', 'الرمل',\n",
    "                         'الرجز', 'الخفيف', 'البسيط', 'المقتضب', 'الهزج', 'المضارع', 'المتدارك']\n",
    "\n",
    "print(elminated_classic_bohor)\n",
    "print(full_bohor_classes)\n",
    "\n",
    "all_filtered_data = all_data_cleaned.loc[all_data_cleaned['Bahr'].isin(full_bohor_classes)]\n",
    "eliminated_filtered_data = all_data_cleaned.loc[all_data_cleaned['Bahr'].isin(elminated_classic_bohor)]\n",
    "\n",
    "#all_filtered_data.head().head()\n",
    "#eliminated_filtered_data.head()\n",
    "#full_filtered_data.iloc[:, 1].value_counts()\n",
    "#eliminated_filtered_data.iloc[:, 1].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's Encode <3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving preprocessors....\n",
      "saved ....\n",
      "saving preprocessors....\n",
      "saved ...\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    Taha; Encoding Full Data classes as OneHot vectors. \n",
    "'''\n",
    "\n",
    "full_data_label_encoder = LabelEncoder()\n",
    "full_data_integer_encoded = full_data_label_encoder.fit_transform(list(all_filtered_data[\"Bahr\"]))\n",
    "# binary encode\n",
    "full_data_onehot_encoder = OneHotEncoder(sparse=False)\n",
    "full_data_integer_encoded = full_data_integer_encoded.reshape(len(full_data_integer_encoded), 1)\n",
    "full_data_bohor_encoded = full_data_onehot_encoder.fit_transform(full_data_integer_encoded)\n",
    "save_h5('../../data/Encoded/8bits/WithoutTashkeel/Full_Data/full_data_Y_Meters.h5', 'Y', full_data_bohor_encoded)\n",
    "save_h5('../../data/Encoded/8bits/WithTashkeel/Full_Data/full_data_Y_Meters.h5', 'Y', full_data_bohor_encoded)\n",
    "#saving with pickle: https://stackoverflow.com/questions/11218477/how-can-i-use-pickle-to-save-a-dict\n",
    "print('saving preprocessors....')\n",
    "with open(\"../../data/Encoded/8bits/encoders_full_dat.pickle\", 'wb') as pre_file:\n",
    "    pickle.dump(full_data_label_encoder, pre_file, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "print('saved ....')\n",
    "\n",
    "\n",
    "'''\n",
    "    Taha; This cell is entirly doublicated.\n",
    "    It Encodes the eliminated data classes.\n",
    "'''\n",
    "eliminated_data_label_encoder = LabelEncoder()\n",
    "eliminated_data_integer_encoded = eliminated_data_label_encoder.fit_transform(list(eliminated_filtered_data[\"Bahr\"]))\n",
    "# binary encode\n",
    "eliminated_data_onehot_encoder = OneHotEncoder(sparse=False)\n",
    "eliminated_data_integer_encoded = eliminated_data_integer_encoded.reshape(len(eliminated_data_integer_encoded), 1)\n",
    "eliminated_data_bohor_encoded = eliminated_data_onehot_encoder.fit_transform(eliminated_data_integer_encoded)\n",
    "save_h5('../../data/Encoded/8bits/WithoutTashkeel/Eliminated/Eliminated_data_Y_Meters.h5', 'Y', eliminated_data_bohor_encoded)\n",
    "save_h5('../../data/Encoded/8bits/WithTashkeel/Eliminated/Eliminated_data_Y_Meters.h5', 'Y', eliminated_data_bohor_encoded)\n",
    "#saving with pickle: https://stackoverflow.com/questions/11218477/how-can-i-use-pickle-to-save-a-dict\n",
    "print('saving preprocessors....')\n",
    "with open(\"../../data/Encoded/8bits/encoders_eliminated_data.pickle\", 'wb') as pre_file:\n",
    "    pickle.dump(eliminated_data_label_encoder, pre_file, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "print('saved ...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full_cleaned_data_with_tashkeel_encoded encoded ..\n",
      "stacked!\n",
      "full_cleaned_data_with_tashkeel_encoded saved ..\n",
      "(1691636, 111, 8)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    * Encoding the full data with Tashkeel\n",
    "'''\n",
    "\n",
    "\n",
    "X = all_filtered_data.Bayt_Text.apply(lambda x: helpers.string_with_tashkeel_vectorizer(x, MAX_LEN_BAYT))\n",
    "print(\"full_cleaned_data_with_tashkeel_encoded encoded ..\")\n",
    "\n",
    "X_stacked = np.stack(X,axis=0)\n",
    "print(\"stacked!\")\n",
    "\n",
    "save_h5('../../data/Encoded/8bits/WithTashkeel/Full_Data/full_data_matrix_with_tashkeel_8bitsEncoding.h5', 'X', X_stacked) \n",
    "print(\"full_cleaned_data_with_tashkeel_encoded saved ..\")\n",
    "print(X_stacked.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eliminated_cleaned_data_with_tashkeel_encoded encoded ..\n",
      "full_cleaned_data_with_tashkeel_encoded saved ..\n",
      "(1670144, 111, 8)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    * Encoding the eleiminated data with Tashkeel\n",
    "'''\n",
    "\n",
    "X = None\n",
    "X_stacked = None\n",
    "\n",
    "X = eliminated_filtered_data.Bayt_Text.apply(lambda x: helpers.string_with_tashkeel_vectorizer(x, MAX_LEN_BAYT))\n",
    "print(\"eliminated_cleaned_data_with_tashkeel_encoded encoded ..\")\n",
    "\n",
    "X_stacked = np.stack(X,axis=0)\n",
    "save_h5('../../data/Encoded/8bits/WithTashkeel/Eliminated/eliminated_data_matrix_with_tashkeel_8bitsEncoding.h5', 'X', X_stacked)\n",
    "\n",
    "print(\"full_cleaned_data_with_tashkeel_encoded saved ..\")\n",
    "print(X_stacked.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    خليليي لا تستعجلا أن تزوودا وأن تجمعا شملي وتن...\n",
       "1    فما لبثن يومن بسابقن مغنمن ولا سرعتي يومن بساب...\n",
       "2    وإن تنظراني اليوم أقض لبانتن وتستوجبا مننن علي...\n",
       "3    لعمرك ما نفسن بجدن رشيدةتن تؤامرني سررن لأصرم ...\n",
       "4    وإن ظهرت منه قوارص جممتن وأفرع في لومي مرارن و...\n",
       "Name: Bayt_Text, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = None\n",
    "X_stacked = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stripping Taskeel\n",
    "all_data_cleaned.Bayt_Text = all_data_cleaned.Bayt_Text.apply(pyarabic.araby.strip_tashkeel)\n",
    "all_filtered_data = all_data_cleaned.loc[all_data_cleaned['Bahr'].isin(full_bohor_classes)]\n",
    "eliminated_filtered_data = all_data_cleaned.loc[all_data_cleaned['Bahr'].isin(elminated_classic_bohor)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    * Encoding all data without Tashkeel\n",
    "'''\n",
    "\n",
    "X = None\n",
    "X_stacked = None\n",
    "\n",
    "X = all_filtered_data.Bayt_Text.apply(lambda x: helpers.string_with_tashkeel_vectorizer(x, MAX_LEN_BAYT))\n",
    "print(\"full_filtered_data_without_tashkeel encoded ..\")\n",
    "\n",
    "X_stacked = np.stack(X, axis=0)\n",
    "save_h5('../../data/Encoded/8bits/WithoutTashkeel/Full_Data/full_data_matrix_without_tashkeel_8bitsEncoding.h5', 'X', X_stacked) \n",
    "print(\"full_filtered_data_without_tashkeel_staked saved ..\")\n",
    "\n",
    "print(X_stacked.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eliminated_filtered_data_without_tashkeel encoded ..\n",
      "eliminated_filtered_data_without_tashkeel_staked saved ..\n",
      "(1670144, 111, 8)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    * Encoding elminated data without Tashkeel\n",
    "'''\n",
    "\n",
    "X = None\n",
    "X_stacked = None\n",
    "\n",
    "X = eliminated_filtered_data.Bayt_Text.apply(lambda x: helpers.string_with_tashkeel_vectorizer(x, MAX_LEN_BAYT))\n",
    "print(\"eliminated_filtered_data_without_tashkeel encoded ..\")\n",
    "\n",
    "X_stacked = np.stack(X, axis=0)\n",
    "save_h5('../../data/Encoded/8bits/WithoutTashkeel/Eliminated/eliminated_data_matrix_without_tashkeel_8bitsEncoding.h5', 'X', X_stacked) \n",
    "print(\"eliminated_filtered_data_without_tashkeel_staked saved ..\")\n",
    "\n",
    "print(X_stacked.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
