{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "At least two variables have the same name: bo",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-9f52768d01ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0msess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_variables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m \u001b[0msaver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSaver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mn1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ma1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ma2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/moroclash/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, var_list, reshape, sharded, max_to_keep, keep_checkpoint_every_n_hours, name, restore_sequentially, saver_def, builder, defer_build, allow_empty, write_version, pad_step_number, save_relative_paths, filename)\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdefer_build\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1140\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1141\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaver_def\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_saver_def\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/moroclash/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1170\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1171\u001b[0m           \u001b[0mrestore_sequentially\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_restore_sequentially\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1172\u001b[0;31m           filename=self._filename)\n\u001b[0m\u001b[1;32m   1173\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaver_def\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1174\u001b[0m       \u001b[0;31m# Since self._name is used as a name_scope by builder(), we are\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/moroclash/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, names_to_saveables, reshape, sharded, max_to_keep, keep_checkpoint_every_n_hours, name, restore_sequentially, filename)\u001b[0m\n\u001b[1;32m    668\u001b[0m         \u001b[0munique\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m     \"\"\"\n\u001b[0;32m--> 670\u001b[0;31m     \u001b[0msaveables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ValidateAndSliceInputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames_to_saveables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    671\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmax_to_keep\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m       \u001b[0mmax_to_keep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/moroclash/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36m_ValidateAndSliceInputs\u001b[0;34m(self, names_to_saveables)\u001b[0m\n\u001b[1;32m    553\u001b[0m     \"\"\"\n\u001b[1;32m    554\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames_to_saveables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m       \u001b[0mnames_to_saveables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBaseSaverBuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpListToDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames_to_saveables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    556\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m     \u001b[0msaveables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/moroclash/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36mOpListToDict\u001b[0;34m(op_list)\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnames_to_saveables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m           raise ValueError(\"At least two variables have the same name: %s\" %\n\u001b[0;32m--> 533\u001b[0;31m                            name)\n\u001b[0m\u001b[1;32m    534\u001b[0m         \u001b[0mnames_to_saveables\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m       \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: At least two variables have the same name: bo"
     ]
    }
   ],
   "source": [
    "class nn(object):\n",
    "    def __init__(self,input_size , hidden_size , output_size):\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        \n",
    "        #weight of input vector\n",
    "        self.ui = tf.Variable(\n",
    "            tf.random_normal([self.input_size,self.hidden_size],\n",
    "                             mean=0,stddev=0.01,seed=1),name='ui')\n",
    "        \n",
    "        #weight of rest gate\n",
    "        self.wr = tf.Variable(\n",
    "            tf.random_normal([self.input_size,self.hidden_size],\n",
    "                             mean=0,stddev=0.01,seed=1),name='wr')\n",
    "        self.br = tf.Variable(\n",
    "            tf.ones([self.hidden_size]),name='br')\n",
    "        \n",
    "        #weight of update gate\n",
    "        self.wz = tf.Variable(\n",
    "            tf.random_normal([self.input_size,self.hidden_size],\n",
    "                             mean=0,stddev=0.01,seed=1),name='wz')\n",
    "        self.bz = tf.Variable(\n",
    "            tf.ones([self.hidden_size]),name='bz')\n",
    "\n",
    "        #weight of hidden layer\n",
    "        self.wh = tf.Variable(\n",
    "            tf.random_normal([self.hidden_size,self.hidden_size],\n",
    "                             mean=0,stddev=0.01,seed=1),name='wh')\n",
    "        \n",
    "        #weight of output layer\n",
    "        self.vo = tf.Variable(\n",
    "            tf.random_normal([self.hidden_size,output_size],\n",
    "                             mean=0,stddev=0.01,seed=1),name='vo')\n",
    "        self.bo = tf.Variable(\n",
    "            tf.ones([self.output_size]),name='bo')\n",
    "        \n",
    "        #define shape of input matrix  \n",
    "        \n",
    "        self.inputs_matrix = tf.placeholder(\n",
    "            dtype=tf.float32 ,shape=[None,None,self.input_size],name='inputs_matrix')\n",
    "        \n",
    "        #prepare input matrix to feed model \n",
    "        # it will make matrix as [m,t,n] --> [t,m,n]\n",
    "        # t : number of time\n",
    "        # n : length of input vector\n",
    "        # m : number of sentences\n",
    "        self.feed_marix = tf.transpose(\n",
    "            self.inputs_matrix,perm=[1,0,2],name='feed_marix')\n",
    "        \n",
    "        #prepare initial state as matrix of zerose (batch_size,hidden_size)\n",
    "        self.initial_state = tf.matmul(\n",
    "            self.feed_marix[0],\n",
    "            tf.zeros([self.input_size,self.hidden_size]),name='initial_state')\n",
    "        \n",
    "        self.a1 = tf.placeholder(tf.float32,name='a1')\n",
    "        self.a1 = tf.placeholder(tf.float32, name='1')\n",
    "        self.a2 = tf.placeholder(tf.float32, name='2')\n",
    "        self.b1= tf.Variable(2.0,name=\"b\")\n",
    "    \n",
    "    def ff(self):\n",
    "        a = tf.multiply(self.a1,self.a2,name=\"abcd\")\n",
    "        return a\n",
    "    def gru(self, previous_hidden_state, x):\n",
    "        \"\"\"gur cell that compute  curent state at time t using\n",
    "           previous state at t-1 and input vector x\n",
    "    \n",
    "        Args:\n",
    "            previous_hidden_state (matrix): previous_state at (t-1) .\n",
    "            x (vector): input vector of char.\n",
    "\n",
    "        Returns:\n",
    "            current_hidden_state: current state\n",
    "\n",
    "        Note:\n",
    "            returned matrix size (batch_number , hidden_unit_size)\n",
    "        \"\"\"\n",
    "        #compute update gate that update state_at_(t-1)\n",
    "        z= tf.sigmoid(tf.matmul(x,self.wz)+ self.bz)\n",
    "        #compute reset gate \n",
    "        r= tf.sigmoid(tf.matmul(x,self.wr)+ self.br)  \n",
    "        #compute internal memory\n",
    "        h_= tf.tanh(tf.matmul(x,self.ui) + tf.matmul(previous_hidden_state,self.wh)*r)\n",
    "        #compute current state\n",
    "        current_hidden_state = tf.multiply((1-z),h_) + tf.multiply(previous_hidden_state,z)\n",
    "        return current_hidden_state  \n",
    "        \n",
    "    def get_states(self):\n",
    "        \"\"\"get all state of batch_number example it accumulate \n",
    "           all states of one sentence matrix like :\n",
    "           S0 = initial_state + x0\n",
    "           S1 = S0 + x1\n",
    "           S2 = S1 + x2\n",
    "                .\n",
    "                .\n",
    "           Sn = Sn-1 + xn\n",
    "           \n",
    "           and for batch_number\n",
    "    \n",
    "        Returns:\n",
    "            all_stats: all state of m example\n",
    "\n",
    "        Note:\n",
    "            returned matrix size (number_time_steps ,batch_number , input_size )\n",
    "        \"\"\"\n",
    "        # apply gru function on all matrix of all batch like\n",
    "        #   state_0 =  gru(initial_state,feed_marix[0])\n",
    "        #   state_1 =  gru(state_0,feed_matrix[1])\n",
    "        all_stats = tf.scan(self.gru,self.feed_marix,self.initial_state,name=\"stats\")\n",
    "        return all_stats        \n",
    "        \n",
    "    def get_output(self,hidden_stat):\n",
    "        \"\"\"apply the hidden_state on RELU activation \n",
    "           function to compute output\n",
    "        \n",
    "        Args:\n",
    "            hidden_stat (matrix): state at time t\n",
    "        \n",
    "        Returns:\n",
    "            output: output matrix\n",
    "\n",
    "        Note:\n",
    "            returned matrix size (batch_number , output_size )\n",
    "        \"\"\"\n",
    "        output = tf.nn.relu(tf.matmul(hidden_stat,self.vo)+self.bo,name='output')\n",
    "        return output\n",
    "        \n",
    "n1 = nn(5,2,3)\n",
    "a = n1.ff()\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "sess.run(a,feed_dict={n1.a1:5,n1.a2:6})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Pramaters/my_test_model'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "saver.save(sess, 'Pramaters/my_test_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from Pramaters/my_test_model\n",
      "150.0\n"
     ]
    }
   ],
   "source": [
    "sess1 = tf.Session()    \n",
    "saver = tf.train.import_meta_graph('Pramaters/my_test_model.meta')\n",
    "saver.restore(sess1,tf.train.latest_checkpoint('Pramaters/'))\n",
    "# op_to_restore = sess1.graph.get_tensor_by_name(\"abcd:0\")\n",
    "# print(sess1.run(op_to_restore))\n",
    "\n",
    "graph = tf.get_default_graph()\n",
    "a1 = graph.get_tensor_by_name('1:0')\n",
    "a2 = graph.get_tensor_by_name('2:0')\n",
    "\n",
    "aa = graph.get_tensor_by_name('abcd:0')\n",
    "\n",
    "print(sess1.run(aa,feed_dict ={a1:15.0,a2:10.0}))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from Pramaters/Model_1_using_GRU\n"
     ]
    }
   ],
   "source": [
    "sess1 = tf.Session()    \n",
    "saver = tf.train.import_meta_graph('Pramaters/Model_1_using_GRU.meta')\n",
    "saver.restore(sess1,tf.train.latest_checkpoint('Pramaters/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Session' object has no attribute 'get_outputs'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-09795263539e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msess1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'Session' object has no attribute 'get_outputs'"
     ]
    }
   ],
   "source": [
    "sess1.get_outputs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
